{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holistic Packet Classification with IDP Common Package\n",
    "\n",
    "This notebook demonstrates how to use the holistic packet classification capability of the IDP Common Package to classify multi-document packets, where each document might span multiple pages. The holistic approach examines the document as a whole to identify boundaries between different document types within the packet.\n",
    "\n",
    "**Key Benefits of Holistic Packet Classification:**\n",
    "1. Properly handles multi-page documents within a packet\n",
    "2. Detects logical document boundaries\n",
    "3. Identifies document types in context of the whole document\n",
    "4. Handles documents where individual pages may not be clearly classifiable on their own\n",
    "\n",
    "The notebook demonstrates how to process a document with:\n",
    "\n",
    "1. OCR Service - Convert a PDF document to text using AWS Textract\n",
    "2. Classification Service - Classify document pages into sections using Bedrock using the multi-model page based method.\n",
    "3. Extraction Service - Extract structured information from sections using Bedrock\n",
    "4. Evaluation Service - Evaluate accuracy of extracted information\n",
    "\n",
    "Each step uses the unified Document object model for data flow and consistency.\n",
    "\n",
    "> **Note**: This notebook uses AWS services including S3, Textract, and Bedrock. You need valid AWS credentials with appropriate permissions to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "The IDP common package supports granular installation through extras. You can install:\n",
    "- `[core]` - Just core functionality \n",
    "- `[ocr]` - OCR service with Textract dependencies\n",
    "- `[classification]` - Classification service dependencies\n",
    "- `[extraction]` - Extraction service dependencies\n",
    "- `[evaluation]` - Evaluation service dependencies\n",
    "- `[all]` - All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: idp_common 0.2.21\n",
      "Uninstalling idp_common-0.2.21:\n",
      "  Successfully uninstalled idp_common-0.2.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Version: 0.2.21\n",
      "Location: /home/ec2-user/miniconda/lib/python3.13/site-packages\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Let's make sure that modules are autoreloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "ROOTDIR=\"../..\"\n",
    "# First uninstall existing package (to ensure we get the latest version)\n",
    "%pip uninstall -y idp_common\n",
    "\n",
    "# Install the IDP common package with all components in development mode\n",
    "%pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[dev, all]\"\n",
    "\n",
    "# Note: We can also install specific components like:\n",
    "# %pip install -q -e \"{ROOTDIR}/lib/idp_common_pkg[ocr,classification,extraction,evaluation]\"\n",
    "\n",
    "# Check installed version\n",
    "%pip show idp_common | grep -E \"Version|Location\"\n",
    "\n",
    "# Optionally use a .env file for environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()  \n",
    "except ImportError:\n",
    "    pass  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup:\n",
      "METRIC_NAMESPACE: IDP-Notebook-Example\n",
      "AWS_REGION: us-west-2\n",
      "Input bucket: idp-notebook-input-912625584728-us-west-2\n",
      "Output bucket: idp-notebook-output-912625584728-us-west-2\n",
      "SAMPLE_PDF_PATH: ../samples/rvl_cdip_package.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "# Import base libraries\n",
    "from idp_common.models import Document, Status, Section, Page\n",
    "from idp_common import ocr, classification, extraction, evaluation\n",
    "\n",
    "# Configure logging \n",
    "logging.basicConfig(level=logging.WARNING)  # Set root logger to WARNING (less verbose)\n",
    "logging.getLogger('idp_common.ocr.service').setLevel(logging.INFO)  # Focus on service logs\n",
    "logging.getLogger('idp_common.bedrock.client').setLevel(logging.DEBUG)  # show prompts\n",
    "logging.getLogger('textractor').setLevel(logging.WARNING)  # Suppress textractor logs\n",
    "logging.getLogger('idp_common.evaluation.service').setLevel(logging.DEBUG)  # Enable evaluation logs\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['METRIC_NAMESPACE'] = 'IDP-Notebook-Example'\n",
    "os.environ['AWS_REGION'] = boto3.session.Session().region_name or 'us-east-1'\n",
    "\n",
    "# Get AWS account ID for unique bucket names\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = os.environ['AWS_REGION']\n",
    "\n",
    "# Define sample PDF path \n",
    "SAMPLE_PDF_PATH = f\"{ROOTDIR}/samples/rvl_cdip_package.pdf\"\n",
    "\n",
    "# Create unique bucket names based on account ID and region\n",
    "input_bucket_name =  os.getenv(\"IDP_INPUT_BUCKET_NAME\", f\"idp-notebook-input-{account_id}-{region}\")\n",
    "output_bucket_name = os.getenv(\"IDP_OUTPUT_BUCKET_NAME\", f\"idp-notebook-output-{account_id}-{region}\")\n",
    "\n",
    "# Helper function to parse S3 URIs\n",
    "def parse_s3_uri(uri):\n",
    "    parts = uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = parts[0]\n",
    "    key = \"/\".join(parts[1:])\n",
    "    return bucket, key\n",
    "\n",
    "# Helper function to load JSON from S3\n",
    "def load_json_from_s3(uri):\n",
    "    bucket, key = parse_s3_uri(uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    return json.loads(content)\n",
    "\n",
    "print(\"Environment setup:\")\n",
    "print(f\"METRIC_NAMESPACE: {os.environ.get('METRIC_NAMESPACE')}\")\n",
    "print(f\"AWS_REGION: {os.environ.get('AWS_REGION')}\")\n",
    "print(f\"Input bucket: {input_bucket_name}\")\n",
    "print(f\"Output bucket: {output_bucket_name}\")\n",
    "print(f\"SAMPLE_PDF_PATH: {SAMPLE_PDF_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set Up S3 Buckets and Upload Sample File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket idp-notebook-input-912625584728-us-west-2 already exists\n",
      "Bucket idp-notebook-output-912625584728-us-west-2 already exists\n",
      "Uploaded sample file to: s3://idp-notebook-input-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf\n"
     ]
    }
   ],
   "source": [
    "# Create S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Function to create a bucket if it doesn't exist\n",
    "def ensure_bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3_client.head_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            if region == 'us-east-1':\n",
    "                s3_client.create_bucket(Bucket=bucket_name)\n",
    "            else:\n",
    "                s3_client.create_bucket(\n",
    "                    Bucket=bucket_name,\n",
    "                    CreateBucketConfiguration={'LocationConstraint': region}\n",
    "                )\n",
    "            print(f\"Created bucket: {bucket_name}\")\n",
    "            \n",
    "            # Wait for bucket to be accessible\n",
    "            waiter = s3_client.get_waiter('bucket_exists')\n",
    "            waiter.wait(Bucket=bucket_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating bucket {bucket_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ensure both buckets exist\n",
    "ensure_bucket_exists(input_bucket_name)\n",
    "ensure_bucket_exists(output_bucket_name)\n",
    "\n",
    "# Upload the sample file to S3\n",
    "sample_file_key = \"sample-\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".pdf\"\n",
    "with open(SAMPLE_PDF_PATH, 'rb') as file_data:\n",
    "    s3_client.upload_fileobj(file_data, input_bucket_name, sample_file_key)\n",
    "\n",
    "print(f\"Uploaded sample file to: s3://{input_bucket_name}/{sample_file_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Set Up Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test configuration created for IDP services with LLM evaluation method and enhanced logging\n"
     ]
    }
   ],
   "source": [
    "# Sample configuration that mimics what would be in DynamoDB\n",
    "CONFIG = {\n",
    "    \"evaluation\": {\n",
    "        \"llm_method\": {\n",
    "            \"model\": \"us.amazon.nova-lite-v1:0\",\n",
    "            \"temperature\": 0.0,\n",
    "            \"top_k\": 5,\n",
    "            \"system_prompt\": \"\"\"You are an evaluator that helps determine if the predicted and expected values match for document attribute extraction. You will consider the context and meaning rather than just exact string matching.\"\"\",\n",
    "            \"task_prompt\": \"\"\"I need to evaluate attribute extraction for a document of class: {DOCUMENT_CLASS}.\n",
    "\n",
    "For the attribute named \"{ATTRIBUTE_NAME}\" described as \"{ATTRIBUTE_DESCRIPTION}\":\n",
    "- Expected value: {EXPECTED_VALUE}\n",
    "- Actual value: {ACTUAL_VALUE}\n",
    "\n",
    "Do these values match in meaning, taking into account formatting differences, word order, abbreviations, and semantic equivalence?\n",
    "Provide your assessment as a JSON with three fields:\n",
    "- \"match\": boolean (true if they match, false if not)\n",
    "- \"score\": number between 0 and 1 representing the confidence/similarity score\n",
    "- \"reason\": brief explanation of your decision\n",
    "\n",
    "Respond ONLY with the JSON and nothing else. Here's the exact format:\n",
    "{\n",
    "  \"match\": true or false,\n",
    "  \"score\": 0.0 to 1.0,\n",
    "  \"reason\": \"Your explanation here\"\n",
    "}\"\"\"\n",
    "        }\n",
    "    },\n",
    "    \"classes\": [\n",
    "        {\n",
    "        \"name\": \"letter\",\n",
    "        \"description\": \"A formal written message that is typically sent from one person to another\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"sender_name\",\n",
    "            \"description\": \"The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature.\",\n",
    "            \"evaluation_method\": \"LLM\" \n",
    "            },\n",
    "            {\n",
    "            \"name\": \"sender_address\",\n",
    "            \"description\": \"The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'.\",\n",
    "            \"evaluation_method\": \"LLM\", \n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"form\",\n",
    "        \"description\": \"A document with blank spaces for filling in information\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"form_type\",\n",
    "            \"description\": \"The category or purpose of the form, such as 'application', 'registration', 'request', etc. May be identified by 'form name', 'document type', or 'form category'.\",\n",
    "            \"evaluation_method\": \"FUZZY\",\n",
    "            \"evaluation_threshold\": \"0.8\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"form_id\",\n",
    "            \"description\": \"The unique identifier for the form, typically a number or alphanumeric code. Often labeled as 'form number', 'id', or 'reference number'.\",\n",
    "            \"evaluation_method\": \"NUMERIC_EXACT\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"email\",\n",
    "        \"description\": \"An electronic message sent from one person to another over a computer network\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"from_address\",\n",
    "            \"description\": \"The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header.\",\n",
    "            # Evaluation method not specified - will default to LLM\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"to_address\",\n",
    "            \"description\": \"The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'.\",\n",
    "            # Evaluation method not specified - will default to LLM\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"specification\",\n",
    "        \"description\": \"A detailed description of technical requirements or characteristics\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"product_name\",\n",
    "            \"description\": \"The name of the item being specified. Look for text labeled as 'product', 'item', or 'model', typically appearing prominently at the beginning.\",\n",
    "            \"evaluation_method\": \"FUZZY\",\n",
    "            \"evaluation_threshold\": 0.7\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"version\",\n",
    "            \"description\": \"The iteration or release number. May be indicated by 'version', 'revision', or 'release', often followed by a number or code.\",\n",
    "            \"evaluation_method\": \"NUMERIC_EXACT\"\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"memo\",\n",
    "        \"description\": \"A brief written message used for internal communication within an organization\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"memo_date\",\n",
    "            \"description\": \"The date when the memo was written. Look for 'date' or 'memo date', typically near the top of the document.\",\n",
    "            \"evaluation_method\": \"EXACT\"\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"from\",\n",
    "            \"description\": \"The person or department that wrote the memo. May be labeled as 'from', 'sender', or 'author'.\",\n",
    "            \"evaluation_method\": \"LLM\", \n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"invoice\",\n",
    "        \"description\": \"A commercial document issued by a seller to a buyer relating to a sale\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"invoice_number\",\n",
    "            \"description\": \"The unique identifier for the invoice. Look for 'invoice no', 'invoice #', or 'bill number', typically near the top of the document.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"invoice_date\",\n",
    "            \"description\": \"The date when the invoice was issued. May be labeled as 'date', 'invoice date', or 'billing date'.\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"resume\",\n",
    "        \"description\": \"A document summarizing a person's background, skills, and qualifications\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"full_name\",\n",
    "            \"description\": \"The complete name of the job applicant, typically appearing prominently at the top of the resume. May be simply labeled as 'name' or 'applicant name'.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"contact_info\",\n",
    "            \"description\": \"The phone number, email, and address of the applicant. Look for a section with 'contact', 'phone', 'email', or 'address', usually near the top of the resume.\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"scientific_publication\",\n",
    "        \"description\": \"A formally published document presenting scientific research findings\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"title\",\n",
    "            \"description\": \"The name of the scientific paper, typically appearing prominently at the beginning. May be labeled as 'title', 'paper title', or 'article title'.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"authors\",\n",
    "            \"description\": \"The researchers who conducted the study and wrote the paper. Look for names after 'authors', 'contributors', or 'researchers', usually following the title.\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"advertisement\",\n",
    "        \"description\": \"A public notice promoting a product, service, or event\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"product_name\",\n",
    "            \"description\": \"The name of the item or service being advertised. Look for prominently displayed text that could be a 'product', 'item', or 'service' name.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"brand\",\n",
    "            \"description\": \"The company or manufacturer of the product. May be indicated by a logo or text labeled as 'brand', 'company', or 'manufacturer'.\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"questionnaire\",\n",
    "        \"description\": \"A set of written questions designed to collect information from respondents\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"form_title\",\n",
    "            \"description\": \"The name or title of the questionnaire. Look for prominently displayed text at the beginning that could be a 'title', 'survey name', or 'questionnaire name'.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"respondent_info\",\n",
    "            \"description\": \"Information about the person completing the questionnaire. May include fields labeled 'respondent', 'participant', or 'name'.\",\n",
    "            }\n",
    "        ]\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"generic\",\n",
    "        \"description\": \"A general document type that doesn't fit into other specific categories\",\n",
    "        \"attributes\": [\n",
    "            {\n",
    "            \"name\": \"document_type\",\n",
    "            \"description\": \"The classification or category of the document. Look for terms like 'type', 'category', or 'class' that indicate what kind of document this is.\",\n",
    "            },\n",
    "            {\n",
    "            \"name\": \"document_date\",\n",
    "            \"description\": \"The date when the document was created. May be labeled as 'date', 'created on', or 'issued on'.\",\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "  \"classification\": {\n",
    "    \"temperature\": \"0\",\n",
    "    \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "    \"classificationMethod\": \"textbasedHolisticClassification\",  # Use holistic packet classification\n",
    "    \"system_prompt\": \"You are a document classification expert who can analyze and classify multiple documents and their page boundaries within a document package from various domains. Your task is to determine the document type based on its content and structure, using the provided document type definitions. Your output must be valid JSON according to the requested format.\",\n",
    "    \"top_k\": \"5\",\n",
    "    \"task_prompt\": \"\"\"The <document-types> XML tags contain a markdown table of known doc types for detection.\n",
    "<document-types>\n",
    "{CLASS_NAMES_AND_DESCRIPTIONS}\n",
    "</document-types>\n",
    "\n",
    "<guidance>\n",
    "Guidance for terminology found in the instructions.\n",
    "    * ordinal_start_page: The one based beginning page of a document segment within the document package.\n",
    "    * ordinal_end_page: The one based ending page of a document segment within the document package.\n",
    "    * document_type: The document type code detected for a document segment.\n",
    "    * Distinct documents of the same type may be adjacent to each other in the packet. Be sure to separate them into different document segments and don't combine them.\n",
    "</guidance>\n",
    "\n",
    "<document-splitting-guidance>\n",
    "When deciding whether pages belong to the same document segment:\n",
    "- Content continuity: Pages with continuing paragraphs, numbered sections, or ongoing narratives likely belong to the same document.\n",
    "- Visual/formatting consistency: Similar layouts, headers, footers, and styling suggest pages belong together.\n",
    "- Logical completion: A document typically has a beginning, middle, and end structure.\n",
    "- Document boundaries: Look for clear indicators of a new document such as new title pages, cover sheets, or significantly different subject matter.\n",
    "- Content similarity: Pages discussing the same topic or subject likely belong to the same document.\n",
    "\n",
    "Pages should be grouped together when they represent a coherent, continuous document, even if they span multiple pages. Split documents only when there is clear evidence that a new, distinct document begins.\n",
    "</document-splitting-guidance>\n",
    "\n",
    "CRITICAL: You must ONLY use document types explicitly listed in the <document-types> section. Do not create, invent, or use any document type not found in this list. If a document doesn't clearly match any listed type, assign it to the most similar listed type or \"other\" if that option is provided.\n",
    "Follow these steps when classifying documents within the document package:\n",
    "1. Examine the document package as a whole, and identify page ranges that are likely to belong to one of the <document-types>.\n",
    "2. Match each page range with an identified document type from the provided list ONLY.\n",
    "3. Identify documents of the same type, that are not the same document but are adjacent to each other in the packet.\n",
    "4. Separate unique documents of the same type adjacent to each other in the packet into distinct document segments. Important: Do not combine distinct documents of the same type into a single document segment.\n",
    "5. For each identified document type, note the ordinal_start_page and ordinal_end_page.\n",
    "6. Compile the classified documents into a list with their respective ordinal_start_page and ordinal_end_page.\n",
    "7. Before finalizing, verify that each document type in your response exactly matches one from the <document-types> list.\n",
    "\n",
    "Return your response as valid JSON according to this format:\n",
    "```json\n",
    "{\n",
    "    \"segments\": [\n",
    "                      {\n",
    "                        \"ordinal_start_page\": 1,\n",
    "                        \"ordinal_end_page\": 2,\n",
    "                        \"type\": \"the first type of document detected\"\n",
    "                      },\n",
    "                      {\n",
    "                        \"ordinal_start_page\": 3,\n",
    "                        \"ordinal_end_page\": 4,\n",
    "                        \"type\": \"the second type of document detected\"\n",
    "                      }\n",
    "                    ]\n",
    "}\n",
    "The <document-text> XML tags contains the text separated into pages from the document package. Each page will begin with a <page-number> XML tag indicating the one based page ordinal of the page text to follow.\n",
    "<<CACHEPOINT>>\n",
    "<document-text>\n",
    "{DOCUMENT_TEXT}\n",
    "</document-text>\n",
    "```\"\"\"\n",
    "  },\n",
    "  \"extraction\": {\n",
    "    \"temperature\": \"0\",\n",
    "    \"model\": \"us.amazon.nova-pro-v1:0\",\n",
    "    \"system_prompt\": \"You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\\n\",\n",
    "    \"top_k\": \"5\",\n",
    "    \"task_prompt\": \"\"\"\n",
    "<background>\n",
    "You are an expert in business document analysis and information extraction. \n",
    "You can understand and extract key information from business documents. \n",
    "<task>\n",
    "Your task is to take the unstructured text provided and convert it into a\n",
    "well-organized table format using JSON. Identify the main entities,\n",
    "attributes, or categories mentioned in the attributes list below and use\n",
    "them as keys in the JSON object. \n",
    "Then, extract the relevant information from the text and populate the\n",
    "corresponding values in the JSON object. \n",
    "Guidelines:\n",
    "Ensure that the data is accurately represented and properly formatted within the JSON structure\n",
    "Include double quotes around all keys and values\n",
    "Do not make up data - only extract information explicitly found in the document\n",
    "Do not use /n for new lines, use a space instead\n",
    "If a field is not found or if unsure, return null\n",
    "All dates should be in MM/DD/YYYY format\n",
    "Do not perform calculations or summations unless totals are explicitly given\n",
    "If an alias is not found in the document, return null\n",
    "Here are the attributes you should extract:\n",
    "<attributes>\n",
    "{ATTRIBUTE_NAMES_AND_DESCRIPTIONS}\n",
    "</attributes>\n",
    "</task>\n",
    "<<CACHEPOINT>>  \n",
    "</background>\n",
    "The document tpe is {DOCUMENT_CLASS}. Here is the document content:\n",
    "<document_ocr_data>\n",
    "{DOCUMENT_TEXT}\n",
    "</document_ocr_data>\n",
    "    \"\"\"\n",
    "  }\n",
    "}\n",
    "\n",
    "print(\"Test configuration created for IDP services with LLM evaluation method and enhanced logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Document with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.ocr.service:OCR Service initialized with features: ['LAYOUT']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created document with ID: rvl-cdip-package\n",
      "Status: QUEUED\n",
      "\n",
      "Processing document with OCR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 2\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 3\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 5\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 10\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 6\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 7\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 4\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 1\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 9\n",
      "INFO:idp_common.ocr.service:Successfully extracted markdown text for page 8\n",
      "INFO:idp_common.ocr.service:Sorting 10 pages by page number\n",
      "INFO:idp_common.ocr.service:OCR processing completed in 5.53 seconds\n",
      "INFO:idp_common.ocr.service:Processed 10 pages, with 0 errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR processing completed in 5.53 seconds\n",
      "Document status: QUEUED\n",
      "Number of pages processed: 10\n",
      "\n",
      "Processed pages:\n",
      "Page 1:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/result.json\n",
      "Page 2:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/result.json\n",
      "Page 3:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/result.json\n",
      "Page 4:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/result.json\n",
      "Page 5:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/result.json\n",
      "Page 6:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/result.json\n",
      "Page 7:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/result.json\n",
      "Page 8:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/result.json\n",
      "Page 9:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/result.json\n",
      "Page 10:\n",
      "  Image URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/image.jpg\n",
      "  Raw Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/rawText.json\n",
      "  Parsed Text URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/result.json\n",
      "\n",
      "Metering:\n",
      "{\"textract/analyze_document-Layout\": {\"pages\": 10}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a new Document\n",
    "document = Document(\n",
    "    id=\"rvl-cdip-package\",\n",
    "    input_bucket=input_bucket_name,\n",
    "    input_key=sample_file_key,\n",
    "    output_bucket=output_bucket_name,\n",
    "    status=Status.QUEUED\n",
    ")\n",
    "\n",
    "print(f\"Created document with ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "\n",
    "# Create OCR service with Textract\n",
    "# Valid features are 'LAYOUT', 'FORMS', 'SIGNATURES', 'TABLES' (uses analyze_document API)\n",
    "# or leave it empty (to use basic detect_document_text API)\n",
    "ocr_service = ocr.OcrService(\n",
    "    region=region,\n",
    "    enhanced_features=['LAYOUT']\n",
    ")\n",
    "\n",
    "# Process document with OCR\n",
    "print(\"\\nProcessing document with OCR...\")\n",
    "start_time = time.time()\n",
    "document = ocr_service.process_document(document)\n",
    "ocr_time = time.time() - start_time\n",
    "\n",
    "print(f\"OCR processing completed in {ocr_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")\n",
    "print(f\"Number of pages processed: {document.num_pages}\")\n",
    "\n",
    "# Show pages information\n",
    "print(\"\\nProcessed pages:\")\n",
    "for page_id, page in document.pages.items():\n",
    "    print(f\"Page {page_id}:\")\n",
    "    print(f\"  Image URI: {page.image_uri}\")\n",
    "    print(f\"  Raw Text URI: {page.raw_text_uri}\")\n",
    "    print(f\"  Parsed Text URI: {page.parsed_text_uri}\")\n",
    "print(\"\\nMetering:\")\n",
    "print(json.dumps(document.metering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classify the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************************************\n",
      "CONFIG classificationMethod: textbasedHolisticClassification\n",
      "*****************************************************************\n",
      "\n",
      "Classifying document...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: The <document-types> XML tags contain a markdown t...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 631 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 2510 words\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1}\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are a document classification expert who can analyze and classify multiple documents and their page boundaries within a document package from various domains. Your task is to determine the document type based on its content and structure, using the provided document type definitions. Your output must be valid JSON according to the requested format.'}]\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': 'The <document-types> XML tags contain a markdown table of known doc types for detection.\\n<document-types>\\n| type | description |\\n| --- | --- |\\n| letter | A formal written message that is typically sent from one person to another |\\n| form | A document with blank spaces for filling in information |\\n| email | An electronic message sent from one person to another over a computer network |\\n| specification | A detailed description of technical requirements or characteristics |\\n| memo | A brief written message used for internal communication within an organization |\\n| invoice | A commercial document issued by a seller to a buyer relating to a sale |\\n| resume | A document summarizing a person\\'s background, skills, and qualifications |\\n| scientific_publication | A formally published document presenting scientific research findings |\\n| advertisement | A public notice promoting a product, service, or event |\\n| questionnaire | A set of written questions designed to collect information from respondents |\\n| generic | A general document type that doesn\\'t fit into other specific categories |\\n</document-types>\\n\\n<guidance>\\nGuidance for terminology found in the instructions.\\n    * ordinal_start_page: The one based beginning page of a document segment within the document package.\\n    * ordinal_end_page: The one based ending page of a document segment within the document package.\\n    * document_type: The document type code detected for a document segment.\\n    * Distinct documents of the same type may be adjacent to each other in the packet. Be sure to separate them into different document segments and don\\'t combine them.\\n</guidance>\\n\\n<document-splitting-guidance>\\nWhen deciding whether pages belong to the same document segment:\\n- Content continuity: Pages with continuing paragraphs, numbered sections, or ongoing narratives likely belong to the same document.\\n- Visual/formatting consistency: Similar layouts, headers, footers, and styling suggest pages belong together.\\n- Logical completion: A document typically has a beginning, middle, and end structure.\\n- Document boundaries: Look for clear indicators of a new document such as new title pages, cover sheets, or significantly different subject matter.\\n- Content similarity: Pages discussing the same topic or subject likely belong to the same document.\\n\\nPages should be grouped together when they represent a coherent, continuous document, even if they span multiple pages. Split documents only when there is clear evidence that a new, distinct document begins.\\n</document-splitting-guidance>\\n\\nCRITICAL: You must ONLY use document types explicitly listed in the <document-types> section. Do not create, invent, or use any document type not found in this list. If a document doesn\\'t clearly match any listed type, assign it to the most similar listed type or \"other\" if that option is provided.\\nFollow these steps when classifying documents within the document package:\\n1. Examine the document package as a whole, and identify page ranges that are likely to belong to one of the <document-types>.\\n2. Match each page range with an identified document type from the provided list ONLY.\\n3. Identify documents of the same type, that are not the same document but are adjacent to each other in the packet.\\n4. Separate unique documents of the same type adjacent to each other in the packet into distinct document segments. Important: Do not combine distinct documents of the same type into a single document segment.\\n5. For each identified document type, note the ordinal_start_page and ordinal_end_page.\\n6. Compile the classified documents into a list with their respective ordinal_start_page and ordinal_end_page.\\n7. Before finalizing, verify that each document type in your response exactly matches one from the <document-types> list.\\n\\nReturn your response as valid JSON according to this format:\\n```json\\n{\\n    \"segments\": [\\n                      {\\n                        \"ordinal_start_page\": 1,\\n                        \"ordinal_end_page\": 2,\\n                        \"type\": \"the first type of document detected\"\\n                      },\\n                      {\\n                        \"ordinal_start_page\": 3,\\n                        \"ordinal_end_page\": 4,\\n                        \"type\": \"the second type of document detected\"\\n                      }\\n                    ]\\n}\\n'}, {'cachePoint': {'type': 'default'}}, {'text': '\\nThe <document-text> XML tags contains the text separated into pages from the document package. Each page will begin with a <page-number> XML tag indicating the one based page ordinal of the page text to follow.\\n<document-text>\\n<page-number>1</page-number>\\n\\n\\nWESTERN DARK FIRED TOBACCO GROWERS\\' ASSOCIATION \\n\\n206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056 \\n\\n(502) 753-3341 FAX (502) 753-0069/3342 \\n\\nOctober 31, 1995 \\n\\nThe Honorable Wendell H. Ford United States Senate Washington, D. C. 20510 \\n\\nDear Senator Ford: \\n\\nOn behalf of the Western Dark Fired Tobacco Growers\\' Association and the 9,000 tobacco producers it represents, I an obligated to convey our strong opposition to the \"Commitment to our Children\\' petition being circulated by several Members of Congress. \\n\\nIn the tobacco industry, no one wants young people to consume tobacco products and age restriction laws are on the books in every state in the nation. We must take action to better enforce these laws, not create more bureaucracy. \\n\\ngovernment bureaucracy, thus destroying our family farms and There are those in our society who want to add inefficient hampering an adult\\'s First Amendment right to the freedom of choice in using a legal product. \\n\\nYou may have been approached by those who say they are supporting Administration (FDA) regulation of tobacco. However, if FDA is given the authority to regulate tobacco because it is a nicotine the cause of youth smoking prevention by pushing the Food and Drug delivery device\\', farmers will be forced to deal with yet another monitored by the United States Department of Agriculture the government agency. Already our producers deal with and are Administration and many others. We know first hand what a Environmental Protection Agency, the Occupational Safety and Health We certainly need your support and involvement to prevent FDA from nightmare federal government regulations can create for farmers. joining the ranks of federal tobacco regulators. \\n\\nChildren\" petition, looking at it for what it is: more anti-tobacco I urge you to consider the consequences of the \"Commitment to Our indoctrination, rather than a solution to a problem which everyone starting with parents, should address in a responsible manner. \\n\\nSincerely, Will E tlack Will E. Clark General Manager \\n\\nTNJB 0008497\\n\\n\\n<page-number>2</page-number>\\n# LAB SERVICES CONSISTENCY REPORT \\n\\nDATE: 2/28/93\\n TECHNICIAN: CC\\n SHIFT: A\\nTrial 8\\n LINE: 2\\n AREA: 52\\nPRODUCT UNIT CODE:\\n0728\\n SAMPLE ID:\\nstuff box 2\\n REASON FOR REQUEST\\ntest\\n\\nREQUESTED DELIVERY TIME:\\n\\nTIME SAMPLE RECEIVED:\\n-\\n TIME ANALYSIS COMPLETED:\\n\\nDATA COMMUNICATED TO\\nGone\\nAT 105\\n\\nPerson\\nTime\\n\\nDRYING TIME\\n\\n\\n\\n\\nA\\tB\\tC\\tD\\tE\\tIN:\\tOUT:\\nSAMPLE &\\tCONTAINER\\tSAMPLE\\tDILUTION\\tDILUTED\\nCONTAINER\\tWEIGHT IN\\tWEIGHT IN\\tFACTOR\\tSAMPLE\\nWEIGHT IN\\tGRAMS\\tGRAMS\\tWEIGHT IN\\nGRAMS\\t(A-B)\\tGRAMS\\nF\\tG\\tH\\tI\\n1159.3\\t6\\t6955. 8\\tWEIGHT IN\\tPAPER\\tFILTER\\tWEIGHT IN\\tORAMS\\tSAMPLE\\tWEIGHT IN\\tPAPER\\tSAMPLE &\\tH-P\\t% CONSISTENCY\\to\\tx D 1 00\\nORAMS\\tGRAMS\\nWET\\tDRY\\nAVERAGE 3.68\\tCONSISTENCY\\tSAMPLE #1 10\\tSAMPLE #7 //\\t2645\\t2853\\t84 568\\t79.235\\t3.366\\t3123\\t3.62\\t3.64\\n15\\nSAMPLE $ 12\\t2847\\t89.776\\t3.411\\t3.77\\nRANGE:\\nMETER READING:\\nCOMMENTS:\\n\\n\\n\\nACONSIST wis\\n\\n\\n2030053328\\n\\n\\n<page-number>3</page-number>\\n# Ashley Bratich \\n\\nFrom: Kelahan, Ben To: TI New York: \\'TI Minnesota Co: Ashley Bratich (MSMAIL) Subject: FW: Morning Team Notes 4/20 Date: Saturday, April 18. 1998 2:09PM \\n\\nOriginal Message From: Byron Nelson (SMTP:bnelson@wka.com] Sent: Friday, April 17. 1998 5:25 PM To: Judy Albert: Carolyn: Jackie Cohen (AWMA): Frank: Goody; Henry: Hollant: Chris Holt; Hurst: Jim; Joe: John; Benjamin Kelahan: Cheryl Klein: Walt Klein: Lbeckwith; Rob Meyne: Mkatz; Morrow; Powers; Randy; Roger; Ron: Shorep; Steve Strawsburg: Suggsm; Matthew Tilley: whitey Co: Bob Fackler: Bob Stone Subject: Morning Team Notes 4/20 \\n\\nFalmouth MA - On 4/15, town meeting representatives defeated by a 84-77 vote a warrant article calling for a 100 percent ban on smoking in restaurants On 4/16, a motion to reconsider the vote was soundly rejected 104-49. The restaurant owner\\'s moderate alternative was not considered because the town counsel found the article to be unconstitutional \\n\\nWaseca County MN - On 4/7 the county commissioners once again tabled consideration of a new tobacco retailing ordinance Waseca is the 11th Minnesota community to put the issue on hold. \\n\\nWadena County, MN - In mid-March the county commissioners tabled consideration of a new tobacco retailing ordinance until 4/23 At that time. they will take up a model ordinance that mirrors the state law. Bob Fackler requests calls to retailers to alert them to attend \\n\\nPage 1\\n\\n\\nTI1716-0284\\n\\n\\n<page-number>4</page-number>\\nLE CHOIHGPRT Mutation ussey - Alyoral 40LF Book No. 354 \\n\\nin Page No 85, NB. 343 \\n\\nObjectives To measure the ability of a test substance to induse mutation\\n at the hypoxanthine gunnine prosphonloryl transferes (hgpat) lear\\n in Chinese Hamster very (CHO) cells on the basis that\\n mutants by viture of the loss of the HGPRT activity are unabe\\n to convert purine analogs, such as a thingsamine (6-ta) to\\n toxic metabilities and hence escape their lethal effects which\\n is however, excountered ly the wild type cells.\\n Naturals and Methods Refer to Standard Operating Procedure PH314.\\n Sponsor: American Cyanamid Company\\n Test Citiete Algoral 40 LF\\n Descuption clean liquid\\n Date Prelimining Cytotorist Instrated 6/3/82\\n Date CHOIHGAET forward bene Mutation Assay Instituted 8/26/82\\n CHO- KI-BH4 Jost 4 7182 received from Oak Ridge national Laborations 7/1/2\\n Routine subculture were done every Friday (a.m.) and Monday (p.m.),\\n where 1x105 cells were subcultined into each of 3-75cm flasks\\n containing IS ml of media FIZFOSIO. CHO KI-BHY fat# 7182 animption\\n treated 7/23/82. Routine subcolture regine camid out.\\n 8/23/82 CHO-KI-BHY cells (for#7182) subcultured into 10-T75cm2\\n flasks (3x10 cells/flook) in IS mlof media FIRESID\\n\\nEggadek 8/23/82\\n\\n8/25/82. CHO-KI.BH4 cells subcultured into 36 - T25 cm2\\n flasks (5x105 cells (flask) in 5ml of media F12 FCMS, in\\n puparation for treatment (2/21/88) FetalBoundem Lvd KC-32 1005\\n\\nTo Page No. 6\\n\\nitnessed & Understood by me,\\nDate\\nInvented by\\nDate\\n knog neech\\n8/25/82\\nRecorded\\nEdmind by D. Good\\n8/25/82\\n\\n\\n<page-number>5</page-number>\\n\\n\\nPeake Printers, Inc. 2500 Schuster Drive Cheverly, Maryland 20781 (301) 341-4600 WASH. 1-800-521-PEAK (301) 792-2704 BALT. (301) 341-1162 FAX \\n\\n# INVOICE \\n\\nBILL TO \\n\\n20050 THE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET, N.W. WASHINGTON DC 20006 \\n\\nTHE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET N.W. WASHINGTON DC 20006 \\n\\n*** INVOICE *** \\n\\nInvoice No: 86239 Invoice Date: 11/12/92 Ship Date: 10/13/92 P.O. Number: Salesman MICHAEL J MCKILLIPS Job Number: 86239 Ship Via: Terms: NET 30 DAYS \\n\\nA Service Charge of 2% per month (24% per year) will be charged if payment not received by end of first month after invoice date \\n\\n\\n\\nDESCRIPTION\\tQUANTITY\\tUL.\\tM\\tUNIT PRICE\\tAMOUNT\\nTWO SIDED DECAL \"IT\\'S THE\\t5000\\t5145.000\\t5145.00\\nLAW--UNDER 18\" PRINTS 2/2,\\n5 1/2 x 7 1/2\"\\nSUB TOTAL\\t5145.00\\nTAX\\t308.70\\nTOTAL INVOICE\\t5453.70\\nInvoice\\tAMT DUE\\t5453.70\\n83829\\tLESS DEPOSIT\\t(11000.00)\\nCREDIT BALANCE\\t$5546.30\\nok- ADCOH\\nfrom 1501 5201\\nsee attached original\\ndeposit / invoice\\nCONFIDENTIAL:\\nMINNESOTA TOBACCO LITIGATION\\n\\n\\n\\nTIMN 0163588 \\n\\nCUSTOMER COPY FEDID +52-0784214 DUNS #003244142 \\n\\n1\\n\\n\\nForm 700 7.88 \\n\\n<page-number>6</page-number>\\nNEWS RELEASE SIZE Dixon DISSENT FEDERAL TRADE COMMISSION Washington, D.C. 20580 Rein 8- 4-67 OFFICE OF INFORMATION 393-6800 Ext. 197 For RELEASE: A.M., Tuesday, August 1, 1967 \\n\\n# FTC TO BEGIN CIGARETTE TESTING \\n\\nThe Federal Trade Commission, having been advised by the staff that the cigarette testing laboratory has satisfactorily completed its trial tests, has now issued directions to commence the first formal test, under the follow- ing conditions: \\n\\n1. Smoke cigarettes to a 23 - butt length, or to the length of the filter and overwrap plus 3 mm. if in excess of 23 -. \\n2. Base results on a test of 100 cigarettes per brand, or type, \\n3. Cigarettes to be tested will be selected on a random basis, as opposed to \"weight selection,\" \\n4. Determine particulate matter on a \"dry\" basis employing the gas chromatography method published by C. H. Sloan and B. J. Sublett in Tobacco Science 9, page 70, 1965, as modified by F. J. Schultz\\' and A. W. Spears\\' report published in Tobacco Vol. 162, No. 24, page 32, dated June 17, 1966, to determine the moisture content, \\n5. Determine and report the \"tar\" content after subtracting moisture and alkaloids (as nicotine) from particulate matter. \\n6. Report tar content to the nearest whole milligram and nicotine content to the nearest 1/10 milligrams. \\nThe Commission directed that the test cover approximately 50 of the major brands and types (many brands are sold as regular, and king size, or filter, etc.) and all brands for which any tar or nicotine statement appears on the label or in the advertising. With respect to the latter, one purpose of the test will be to determine the accuracy of such statement. Cigarettes for testing will be purchased on the open market in 50 localities throughout the United States. \\nIn determining the foregoing procedures, the Commission relied substan- tially upon a record including written presentation by interested persons and oral testimony offered at a public hearing on November 30, 1966, which was held \"to assist the Commission in determining what action, if any, should be taken in the public interest with respect to modifying or amplifying the Cambridge Filter Method. and the form in which test results should be expressed.\" At the hearing the Commission received numerous submissions re- flecting a variety of modifications of the Cambridge Filter Method that have been adopted by different groups engaged in testing cigarettes. No test can precisely duplicate conditions of actual human smoking and, within fairly wide limits, no one method can be said to be either \"right\" or \"wrong.\" The Commission considers it most important that the test results be based on a reasonable standardized method and that they be capable of being presented to the public in a manner that is readily understandable. Although minor variations may not make one testing method \"better\" than another, the public \\nyour to Mission Byown Apples a Wolfe, Lane A7h7 \\n00 \\n\\nfrom Public Health ack\\n\\nBearing FTC July hise adv\\n\\n\\n<page-number>7</page-number>\\n# PLEASE TELL US WHAT YOU THINK \\n\\nHow satisfied were you in each of the following areas: \\n\\nNeither\\n\\nVery Somewhat Satisfied Nor Somewhat\\nVery\\n Satisfied Satisfied Dissatisfied Dissatisfied Dissatisfied\\n\\n1. PHONE CALL\\n\\nWas our representative\\n courteous and polite?\\n\\nWas our representative\\n knowledgeable?\\n\\nWas your question/request\\n handled?\\n\\n2. Which ONE of the following statements BEST describes the way you feel about R. J.\\n Reynolds\\' response to your request for assistance?\\n\\nI was very satisfied\\nRequested a Catalog\\n I was somewhat satisfied\\n\\nI was neither satisfied nor dissatisfied\\n\\nI was somewhat dissatisfied\\n\\nI was very dissatisfied\\n\\n3. Based on the service you received, will you continue to purchase the brand of cigarettes\\n you contacted us about?\\n\\nI Definitely\\nI Probably\\nI Might or\\nI Probably\\nI Definitely\\n Would\\nWould\\nMight Not\\nWould Not\\nWould Not\\n\\n4. Based on the service you received, would you recommend this brand of cigarettes to an\\n adult smoker (21 years of age or older) who currently smokes a competitive brand?\\n\\nI Definitely I Probably I Might or\\nI Probably\\nI Definitely\\n Would\\nWould\\nMight Not\\nWould Not\\nWould Not\\n\\n\\n52435 9399 \\n\\n<page-number>8</page-number>\\n# BIOGRAPHICAL SKETCH \\n\\nGive the following information for the key personnel and consultants listed on page 2 Begin with the Principal Investigator/Program Director Photocopy this page for each person \\n\\n\\n\\nNAME\\tPOSITION TITLE\\tBIRTHDATE (Mo. Day, Yr.)\\nMario Stevenson\\tAssistant Professor\\tMay 11, 1957\\n\\n\\n\\n\\n\\nEDUCATION (Begin with baccalaureate or other initial professional education such as nursing and include postdoctoral training)\\nINSTITUTION AND LOCATION\\nYEAR\\nDEGREE\\tCONFERRED\\tFIELD OF STUDY\\nGlasgow College of Technology\\tB.Sc.\\t1979\\tBiochemistry\\nGlasgow, Scotland\\nUniversity of Strathclyde\\tPh.D.\\t1984\\tBiochemistry\\nGlasgow, Scotland\\n\\n\\n\\nRESEARCH AND PROFESSIONAL EXPERIENCE Concluding with present position list in chronological order, previous employment, experience and honors. Include present membership on any Federal Government public advisory committee List. in chronological order. the titles and com plete references to all publications during the past three years and to representative earlier publications pertinent to this application DO NO EXCEED TWO PAGES \\n\\n## EXPERIENCE \\n\\n8/80 5/84: Research Associate, Department of Pharmacology, University of Strathclyde, Glasgow, Scotland. 10/84 5/86: Research Fellow, Department of Pathology & Microbiology, University of Nebraska Medical Center Omaha, Nebranka 6/86 6/87: Instructor, Department of Pathology & Microbiology University of Nebracka Medical Center Omaha, Nebraska 7/87 - Present Assistant Professor, Department of Pathology & Microbiology, University of Nebraska Medical Center Omaha, Nebraska \\n\\n## HONORS \\n\\nBritish Pharmaceutical Association Travel Award. Glasgow College of Technology, Bachelor of Science with Honors. \\n\\n## PUBLICATIONS \\n\\n1. Stevenson, M., Baillie, A.J., and Richards, R.M.E. Enhanced activity of Streptomycin and Chloramphenicol against intracellular E. coli in the J774 macrophage cell line mediated by lipsome delivery. Antimicrob. Agents. Chenother. 24:742-749, 1985. \\n2. Stevenson. M., Baillie, A.J., and Richards, R.M.E. An in-vitro model of intracellular bacterial infection using the murine macrophage cell line J774.2. J. Phar. Pharmacol. 36:90-94, 1984. \\n3. Stevenson, M., Baillie, A.J., and Richards, R.M.E. Quantification of liposomal uptake in J774 macrophages -- a flow cytometric study. J. Pharm. Pharmacol. 38:120-126, 1985. \\n4. Volsky, D.J., Wu. Y.T., Stevenson, M., Sinangil, F., Merino, F., Rodriguez, L., and Godoy, G. Antibodies to HTLV-III/LAV in Vene- zuelan patients with acute malaria infection (P. falciparum and P. vivax). New England J. Med., 314, #10:647-648, 1986. \\n5. Shapiro. I., Stevenson, M., Sinangil, F., and Volsky, D.J. Transfection of lysphoblastoid cells: expression of co- transfected DNA and selection of transfected cell lines. Somatic cell & Mol. Genetics, 12:351-356, 1986. \\n\\n<page-number>9</page-number>\\n# CURRICULUM VITAE \\n\\nSURNAME: Kalina BIRTHDATE January 21, 1938 \\n\\nFIRST NAME: Moshe \\n\\nEDUCATION BACKGROUND \\n\\n\\n\\nFrom-To\\tInstitution\\tArea of specialization\\tDegree\\n1958-1961\\tHebrew University of Jerusalem\\tAgriculture\\tR So\\n1961-1964\\tHebrew University of Jerusalem\\tBiochemistry\\tM So\\n1964-1967\\tUniv. of London, King\\'s College\\tCytochemistry\\tPh D.\\n\\n\\n\\nMajor research interest: The surfactant system: cell biological approach \\n\\n## EMPLOYMENT (start with present position) \\n\\n\\n\\nFrom-To\\tInstitution\\tResearch area\\tTitle\\n1978-present\\tDept. of Histology, Tel Aviv niversity\\tThe surfactant system\\tAssoc Prof.\\n1972-1978\\tDept. of Histology & Cell Biology, -\\tCytatoxic lymphocyte\\tSen Lectur.\\n1967-1978\\tDept. of Histology&Cell Biology, 11\\tHistochemistry\\tLecturer\\n1990-1991\\tNational Jewish Hospital, Denver\\tThe surfactant system\\tVisit,Ass\\n1984-1985\\tPostgraduate Medical School London\\tImmunory tochem-endocris Vist Ass.\\nsystem\\n1976-1977\\tDept. of Anatomy, UCLA\\tThe surfactant system\\tVist Ass.\\tProf\\n1972-1973\\tJohns Hopkins University\\tE.M. cytochenistry\\tVist,Ass.\\tProf\\nList grants and contracts on related or other subjects currently received by investigator from BSF and other sources.\\nFrom-To\\tTitle of project\\tSources\\tproject\\t% Time/\\tTotal grant\\n\\n\\n\\nPro \\n\\nProf \\n\\n50601911\\n\\n\\n<page-number>10</page-number>\\nFraserSmith THING MARKETING *STRATEGIC PLANNING . PROMOTION \\n\\n# MEMORANDUM \\n\\n\\n\\nTo:\\tHoward Goldfrach\\tDate:\\tApril 3, 1987\\nKathy Leiber\\nFrom:\\tMel Fallis\\tRe:\\tBlack Consumer\\nMarket Promotion\\nDevelopment\\n\\n\\n\\nAttached you will find the proposed project development timetable for the Situation Analysis and Campaign Development phases for Benson & Hedges and Virginia Slims. At the scheduled meetings on April 9th with Howard at 1:30PM and Kathy at 3PM, concentration will be placed on the subjects for review and evaluation identified for April. I am very interested in obtaining copies of as much information as available about the industry, category, consumer dynamics and promotion activities. \\n\\nIf there are questions prior to our meeting, please don\\'t hesitate to call. \\n\\nMel \\n\\nCC: Ellen Merlo Terry Fraser Emmie LaBauve \\n\\n475 10th AVENUE . SUITE 800 . NEW YORK, N.Y. 10018 . (212) 564-8588\\n\\n\\n\\n</document-text>\\n```'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 2.47s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'b3683972-3e4b-4529-b3bc-5cc285cda9fd', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:19:54 GMT', 'content-type': 'application/json', 'content-length': '1307', 'connection': 'keep-alive', 'x-amzn-requestid': 'b3683972-3e4b-4529-b3bc-5cc285cda9fd'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n    \"segments\": [\\n        {\\n            \"ordinal_start_page\": 1,\\n            \"ordinal_end_page\": 2,\\n            \"type\": \"letter\"\\n        },\\n        {\\n            \"ordinal_start_page\": 3,\\n            \"ordinal_end_page\": 4,\\n            \"type\": \"email\"\\n        },\\n        {\\n            \"ordinal_start_page\": 5,\\n            \"ordinal_end_page\": 5,\\n            \"type\": \"invoice\"\\n        },\\n        {\\n            \"ordinal_start_page\": 6,\\n            \"ordinal_end_page\": 6,\\n            \"type\": \"adv... [truncated]'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 4680, 'outputTokens': 263, 'totalTokens': 6044, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 1101}, 'metrics': {'latencyMs': 2207}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 4680, 'outputTokens': 263, 'totalTokens': 6044, 'cacheReadInputTokens': 0, 'cacheWriteInputTokens': 1101}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed in 4.21 seconds\n",
      "Document status: QUEUED\n"
     ]
    }
   ],
   "source": [
    "# Verify that Config specifies => \"classificationMethod\": \"textbasedHolisticClassification\"\n",
    "print(\"*****************************************************************\")\n",
    "print(f'CONFIG classificationMethod: {CONFIG[\"classification\"].get(\"classificationMethod\")}')\n",
    "print(\"*****************************************************************\")\n",
    "\n",
    "# Create classification service with Bedrock backend\n",
    "# The classification method is set in the config\n",
    "classification_service = classification.ClassificationService(\n",
    "    config=CONFIG, \n",
    "    backend=\"bedrock\" \n",
    ")\n",
    "\n",
    "# Classify the document\n",
    "print(\"\\nClassifying document...\")\n",
    "start_time = time.time()\n",
    "document = classification_service.classify_document(document)\n",
    "classification_time = time.time() - start_time\n",
    "print(f\"Classification completed in {classification_time:.2f} seconds\")\n",
    "print(f\"Document status: {document.status.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected sections:\n",
      "Section 1: letter\n",
      "  Pages: ['1', '2']\n",
      "Section 2: email\n",
      "  Pages: ['3', '4']\n",
      "Section 3: invoice\n",
      "  Pages: ['5']\n",
      "Section 4: advertisement\n",
      "  Pages: ['6']\n",
      "Section 5: questionnaire\n",
      "  Pages: ['7']\n",
      "Section 6: resume\n",
      "  Pages: ['8', '9']\n",
      "Section 7: memo\n",
      "  Pages: ['10']\n",
      "\n",
      "Page-level classifications:\n",
      "Page 1: letter\n",
      "Page 10: memo\n",
      "Page 2: letter\n",
      "Page 3: email\n",
      "Page 4: email\n",
      "Page 5: invoice\n",
      "Page 6: advertisement\n",
      "Page 7: questionnaire\n",
      "Page 8: resume\n",
      "Page 9: resume\n"
     ]
    }
   ],
   "source": [
    "# Show classification results\n",
    "if document.sections:\n",
    "    print(\"\\nDetected sections:\")\n",
    "    for section in document.sections:\n",
    "        print(f\"Section {section.section_id}: {section.classification}\")\n",
    "        print(f\"  Pages: {section.page_ids}\")\n",
    "else:\n",
    "    print(\"\\nNo sections detected\")\n",
    "\n",
    "# Show page classification\n",
    "print(\"\\nPage-level classifications:\")\n",
    "for page_id, page in sorted(document.pages.items()):\n",
    "    print(f\"Page {page_id}: {page.classification}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Information from Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting information from document sections...\n",
      "\n",
      "Processing section 1 (class: letter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: \n",
      "<background>\n",
      "You are an expert in business docume...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 245 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 480 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1}\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\\n'}]\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"\\n<background>\\nYou are an expert in business document analysis and information extraction. \\nYou can understand and extract key information from business documents. \\n<task>\\nYour task is to take the unstructured text provided and convert it into a\\nwell-organized table format using JSON. Identify the main entities,\\nattributes, or categories mentioned in the attributes list below and use\\nthem as keys in the JSON object. \\nThen, extract the relevant information from the text and populate the\\ncorresponding values in the JSON object. \\nGuidelines:\\nEnsure that the data is accurately represented and properly formatted within the JSON structure\\nInclude double quotes around all keys and values\\nDo not make up data - only extract information explicitly found in the document\\nDo not use /n for new lines, use a space instead\\nIf a field is not found or if unsure, return null\\nAll dates should be in MM/DD/YYYY format\\nDo not perform calculations or summations unless totals are explicitly given\\nIf an alias is not found in the document, return null\\nHere are the attributes you should extract:\\n<attributes>\\nsender_name  \\t[ The name of the person or entity who wrote or sent the letter. Look for text following or near terms like 'from', 'sender', 'authored by', 'written by', or at the end of the letter before a signature. ]\\nsender_address  \\t[ The physical address of the sender, typically appearing at the top of the letter. May be labeled as 'address', 'location', or 'from address'. ]\\n</attributes>\\n</task>\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '  \\n</background>\\nThe document tpe is letter. Here is the document content:\\n<document_ocr_data>\\n\\n\\nWESTERN DARK FIRED TOBACCO GROWERS\\' ASSOCIATION \\n\\n206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056 \\n\\n(502) 753-3341 FAX (502) 753-0069/3342 \\n\\nOctober 31, 1995 \\n\\nThe Honorable Wendell H. Ford United States Senate Washington, D. C. 20510 \\n\\nDear Senator Ford: \\n\\nOn behalf of the Western Dark Fired Tobacco Growers\\' Association and the 9,000 tobacco producers it represents, I an obligated to convey our strong opposition to the \"Commitment to our Children\\' petition being circulated by several Members of Congress. \\n\\nIn the tobacco industry, no one wants young people to consume tobacco products and age restriction laws are on the books in every state in the nation. We must take action to better enforce these laws, not create more bureaucracy. \\n\\ngovernment bureaucracy, thus destroying our family farms and There are those in our society who want to add inefficient hampering an adult\\'s First Amendment right to the freedom of choice in using a legal product. \\n\\nYou may have been approached by those who say they are supporting Administration (FDA) regulation of tobacco. However, if FDA is given the authority to regulate tobacco because it is a nicotine the cause of youth smoking prevention by pushing the Food and Drug delivery device\\', farmers will be forced to deal with yet another monitored by the United States Department of Agriculture the government agency. Already our producers deal with and are Administration and many others. We know first hand what a Environmental Protection Agency, the Occupational Safety and Health We certainly need your support and involvement to prevent FDA from nightmare federal government regulations can create for farmers. joining the ranks of federal tobacco regulators. \\n\\nChildren\" petition, looking at it for what it is: more anti-tobacco I urge you to consider the consequences of the \"Commitment to Our indoctrination, rather than a solution to a problem which everyone starting with parents, should address in a responsible manner. \\n\\nSincerely, Will E tlack Will E. Clark General Manager \\n\\nTNJB 0008497\\n\\n# LAB SERVICES CONSISTENCY REPORT \\n\\nDATE: 2/28/93\\n TECHNICIAN: CC\\n SHIFT: A\\nTrial 8\\n LINE: 2\\n AREA: 52\\nPRODUCT UNIT CODE:\\n0728\\n SAMPLE ID:\\nstuff box 2\\n REASON FOR REQUEST\\ntest\\n\\nREQUESTED DELIVERY TIME:\\n\\nTIME SAMPLE RECEIVED:\\n-\\n TIME ANALYSIS COMPLETED:\\n\\nDATA COMMUNICATED TO\\nGone\\nAT 105\\n\\nPerson\\nTime\\n\\nDRYING TIME\\n\\n\\n\\n\\nA\\tB\\tC\\tD\\tE\\tIN:\\tOUT:\\nSAMPLE &\\tCONTAINER\\tSAMPLE\\tDILUTION\\tDILUTED\\nCONTAINER\\tWEIGHT IN\\tWEIGHT IN\\tFACTOR\\tSAMPLE\\nWEIGHT IN\\tGRAMS\\tGRAMS\\tWEIGHT IN\\nGRAMS\\t(A-B)\\tGRAMS\\nF\\tG\\tH\\tI\\n1159.3\\t6\\t6955. 8\\tWEIGHT IN\\tPAPER\\tFILTER\\tWEIGHT IN\\tORAMS\\tSAMPLE\\tWEIGHT IN\\tPAPER\\tSAMPLE &\\tH-P\\t% CONSISTENCY\\to\\tx D 1 00\\nORAMS\\tGRAMS\\nWET\\tDRY\\nAVERAGE 3.68\\tCONSISTENCY\\tSAMPLE #1 10\\tSAMPLE #7 //\\t2645\\t2853\\t84 568\\t79.235\\t3.366\\t3123\\t3.62\\t3.64\\n15\\nSAMPLE $ 12\\t2847\\t89.776\\t3.411\\t3.77\\nRANGE:\\nMETER READING:\\nCOMMENTS:\\n\\n\\n\\nACONSIST wis\\n\\n\\n2030053328\\n\\n</document_ocr_data>\\n    '}, {'image': '[image_data]'}, {'image': '[image_data]'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 1.83s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '7d52b622-82aa-4080-be5c-5782288fcfbf', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:21:45 GMT', 'content-type': 'application/json', 'content-length': '430', 'connection': 'keep-alive', 'x-amzn-requestid': '7d52b622-82aa-4080-be5c-5782288fcfbf'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"sender_name\": \"Will E. Clark\",\\n  \"sender_address\": \"206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056\"\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 2316, 'outputTokens': 50, 'totalTokens': 3460, 'cacheReadInputTokens': 1094, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 1529}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 2316, 'outputTokens': 50, 'totalTokens': 3460, 'cacheReadInputTokens': 1094, 'cacheWriteInputTokens': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 1 completed in 4.12 seconds\n",
      "\n",
      "Processing section 2 (class: email)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: \n",
      "<background>\n",
      "You are an expert in business docume...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 224 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 474 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1}\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\\n'}]\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"\\n<background>\\nYou are an expert in business document analysis and information extraction. \\nYou can understand and extract key information from business documents. \\n<task>\\nYour task is to take the unstructured text provided and convert it into a\\nwell-organized table format using JSON. Identify the main entities,\\nattributes, or categories mentioned in the attributes list below and use\\nthem as keys in the JSON object. \\nThen, extract the relevant information from the text and populate the\\ncorresponding values in the JSON object. \\nGuidelines:\\nEnsure that the data is accurately represented and properly formatted within the JSON structure\\nInclude double quotes around all keys and values\\nDo not make up data - only extract information explicitly found in the document\\nDo not use /n for new lines, use a space instead\\nIf a field is not found or if unsure, return null\\nAll dates should be in MM/DD/YYYY format\\nDo not perform calculations or summations unless totals are explicitly given\\nIf an alias is not found in the document, return null\\nHere are the attributes you should extract:\\n<attributes>\\nfrom_address  \\t[ The email address of the sender. Look for text following 'from', 'sender', or 'sent by', typically at the beginning of the email header. ]\\nto_address  \\t[ The email address of the primary recipient. May be labeled as 'to', 'recipient', or 'sent to'. ]\\n</attributes>\\n</task>\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': \"  \\n</background>\\nThe document tpe is email. Here is the document content:\\n<document_ocr_data>\\n# Ashley Bratich \\n\\nFrom: Kelahan, Ben To: TI New York: 'TI Minnesota Co: Ashley Bratich (MSMAIL) Subject: FW: Morning Team Notes 4/20 Date: Saturday, April 18. 1998 2:09PM \\n\\nOriginal Message From: Byron Nelson (SMTP:bnelson@wka.com] Sent: Friday, April 17. 1998 5:25 PM To: Judy Albert: Carolyn: Jackie Cohen (AWMA): Frank: Goody; Henry: Hollant: Chris Holt; Hurst: Jim; Joe: John; Benjamin Kelahan: Cheryl Klein: Walt Klein: Lbeckwith; Rob Meyne: Mkatz; Morrow; Powers; Randy; Roger; Ron: Shorep; Steve Strawsburg: Suggsm; Matthew Tilley: whitey Co: Bob Fackler: Bob Stone Subject: Morning Team Notes 4/20 \\n\\nFalmouth MA - On 4/15, town meeting representatives defeated by a 84-77 vote a warrant article calling for a 100 percent ban on smoking in restaurants On 4/16, a motion to reconsider the vote was soundly rejected 104-49. The restaurant owner's moderate alternative was not considered because the town counsel found the article to be unconstitutional \\n\\nWaseca County MN - On 4/7 the county commissioners once again tabled consideration of a new tobacco retailing ordinance Waseca is the 11th Minnesota community to put the issue on hold. \\n\\nWadena County, MN - In mid-March the county commissioners tabled consideration of a new tobacco retailing ordinance until 4/23 At that time. they will take up a model ordinance that mirrors the state law. Bob Fackler requests calls to retailers to alert them to attend \\n\\nPage 1\\n\\n\\nTI1716-0284\\n\\nLE CHOIHGPRT Mutation ussey - Alyoral 40LF Book No. 354 \\n\\nin Page No 85, NB. 343 \\n\\nObjectives To measure the ability of a test substance to induse mutation\\n at the hypoxanthine gunnine prosphonloryl transferes (hgpat) lear\\n in Chinese Hamster very (CHO) cells on the basis that\\n mutants by viture of the loss of the HGPRT activity are unabe\\n to convert purine analogs, such as a thingsamine (6-ta) to\\n toxic metabilities and hence escape their lethal effects which\\n is however, excountered ly the wild type cells.\\n Naturals and Methods Refer to Standard Operating Procedure PH314.\\n Sponsor: American Cyanamid Company\\n Test Citiete Algoral 40 LF\\n Descuption clean liquid\\n Date Prelimining Cytotorist Instrated 6/3/82\\n Date CHOIHGAET forward bene Mutation Assay Instituted 8/26/82\\n CHO- KI-BH4 Jost 4 7182 received from Oak Ridge national Laborations 7/1/2\\n Routine subculture were done every Friday (a.m.) and Monday (p.m.),\\n where 1x105 cells were subcultined into each of 3-75cm flasks\\n containing IS ml of media FIZFOSIO. CHO KI-BHY fat# 7182 animption\\n treated 7/23/82. Routine subcolture regine camid out.\\n 8/23/82 CHO-KI-BHY cells (for#7182) subcultured into 10-T75cm2\\n flasks (3x10 cells/flook) in IS mlof media FIRESID\\n\\nEggadek 8/23/82\\n\\n8/25/82. CHO-KI.BH4 cells subcultured into 36 - T25 cm2\\n flasks (5x105 cells (flask) in 5ml of media F12 FCMS, in\\n puparation for treatment (2/21/88) FetalBoundem Lvd KC-32 1005\\n\\nTo Page No. 6\\n\\nitnessed & Understood by me,\\nDate\\nInvented by\\nDate\\n knog neech\\n8/25/82\\nRecorded\\nEdmind by D. Good\\n8/25/82\\n\\n</document_ocr_data>\\n    \"}, {'image': '[image_data]'}, {'image': '[image_data]'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 1.53s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '3f4de764-f8dd-45b3-9092-b665ac2b3152', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:21:48 GMT', 'content-type': 'application/json', 'content-length': '395', 'connection': 'keep-alive', 'x-amzn-requestid': '3f4de764-f8dd-45b3-9092-b665ac2b3152'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"from_address\": \"Kelahan, Ben\",\\n  \"to_address\": \"TI New York; \\'TI Minnesota\"\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 2445, 'outputTokens': 30, 'totalTokens': 3522, 'cacheReadInputTokens': 1047, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 1271}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 2445, 'outputTokens': 30, 'totalTokens': 3522, 'cacheReadInputTokens': 1047, 'cacheWriteInputTokens': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 2 completed in 3.14 seconds\n",
      "\n",
      "Processing section 3 (class: invoice)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:Found <<CACHEPOINT>> tags in text content: \n",
      "<background>\n",
      "You are an expert in business docume...\n",
      "DEBUG:idp_common.bedrock.client:Split text into 2 parts at cachepoint tags\n",
      "DEBUG:idp_common.bedrock.client:Text part 1: 224 words\n",
      "DEBUG:idp_common.bedrock.client:Inserting cachePoint #1 after text part 1\n",
      "DEBUG:idp_common.bedrock.client:Text part 2: 185 words\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in image content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Processed content with 1 cachepoint insertions\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-pro-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0, 'topP': 0.1}\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are a document assistant. Respond only with JSON. Never make up data, only provide data found in the document being provided.\\n'}]\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': \"\\n<background>\\nYou are an expert in business document analysis and information extraction. \\nYou can understand and extract key information from business documents. \\n<task>\\nYour task is to take the unstructured text provided and convert it into a\\nwell-organized table format using JSON. Identify the main entities,\\nattributes, or categories mentioned in the attributes list below and use\\nthem as keys in the JSON object. \\nThen, extract the relevant information from the text and populate the\\ncorresponding values in the JSON object. \\nGuidelines:\\nEnsure that the data is accurately represented and properly formatted within the JSON structure\\nInclude double quotes around all keys and values\\nDo not make up data - only extract information explicitly found in the document\\nDo not use /n for new lines, use a space instead\\nIf a field is not found or if unsure, return null\\nAll dates should be in MM/DD/YYYY format\\nDo not perform calculations or summations unless totals are explicitly given\\nIf an alias is not found in the document, return null\\nHere are the attributes you should extract:\\n<attributes>\\ninvoice_number  \\t[ The unique identifier for the invoice. Look for 'invoice no', 'invoice #', or 'bill number', typically near the top of the document. ]\\ninvoice_date  \\t[ The date when the invoice was issued. May be labeled as 'date', 'invoice date', or 'billing date'. ]\\n</attributes>\\n</task>\\n\"}, {'cachePoint': {'type': 'default'}}, {'text': '  \\n</background>\\nThe document tpe is invoice. Here is the document content:\\n<document_ocr_data>\\n\\n\\nPeake Printers, Inc. 2500 Schuster Drive Cheverly, Maryland 20781 (301) 341-4600 WASH. 1-800-521-PEAK (301) 792-2704 BALT. (301) 341-1162 FAX \\n\\n# INVOICE \\n\\nBILL TO \\n\\n20050 THE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET, N.W. WASHINGTON DC 20006 \\n\\nTHE TOBACCO INSTITUTE ATTN: ANNE CANNELL 1875 I STREET N.W. WASHINGTON DC 20006 \\n\\n*** INVOICE *** \\n\\nInvoice No: 86239 Invoice Date: 11/12/92 Ship Date: 10/13/92 P.O. Number: Salesman MICHAEL J MCKILLIPS Job Number: 86239 Ship Via: Terms: NET 30 DAYS \\n\\nA Service Charge of 2% per month (24% per year) will be charged if payment not received by end of first month after invoice date \\n\\n\\n\\nDESCRIPTION\\tQUANTITY\\tUL.\\tM\\tUNIT PRICE\\tAMOUNT\\nTWO SIDED DECAL \"IT\\'S THE\\t5000\\t5145.000\\t5145.00\\nLAW--UNDER 18\" PRINTS 2/2,\\n5 1/2 x 7 1/2\"\\nSUB TOTAL\\t5145.00\\nTAX\\t308.70\\nTOTAL INVOICE\\t5453.70\\nInvoice\\tAMT DUE\\t5453.70\\n83829\\tLESS DEPOSIT\\t(11000.00)\\nCREDIT BALANCE\\t$5546.30\\nok- ADCOH\\nfrom 1501 5201\\nsee attached original\\ndeposit / invoice\\nCONFIDENTIAL:\\nMINNESOTA TOBACCO LITIGATION\\n\\n\\n\\nTIMN 0163588 \\n\\nCUSTOMER COPY FEDID +52-0784214 DUNS #003244142 \\n\\n1\\n\\n\\nForm 700 7.88 \\n</document_ocr_data>\\n    '}, {'image': '[image_data]'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 1.33s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '71b828a6-1fa6-4cf7-8838-10dd16c107f5', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:21:51 GMT', 'content-type': 'application/json', 'content-length': '374', 'connection': 'keep-alive', 'x-amzn-requestid': '71b828a6-1fa6-4cf7-8838-10dd16c107f5'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '{\\n  \"invoice_number\": \"86239\",\\n  \"invoice_date\": \"11/12/1992\"\\n}'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 1063, 'outputTokens': 33, 'totalTokens': 2002, 'cacheReadInputTokens': 906, 'cacheWriteInputTokens': 0}, 'metrics': {'latencyMs': 1133}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 1063, 'outputTokens': 33, 'totalTokens': 2002, 'cacheReadInputTokens': 906, 'cacheWriteInputTokens': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction for section 3 completed in 2.68 seconds\n",
      "\n",
      "Extraction for first 3 sections complete.\n"
     ]
    }
   ],
   "source": [
    "# Create extraction service with Bedrock\n",
    "extraction_service = extraction.ExtractionService(config=CONFIG)\n",
    "\n",
    "print(\"\\nExtracting information from document sections...\")\n",
    "extracted_results = {}\n",
    "\n",
    "n = 3 # Only process first 3 sections to save time\n",
    "# Process each section directly using the section_id\n",
    "for section in document.sections[:n]:  \n",
    "    print(f\"\\nProcessing section {section.section_id} (class: {section.classification})\")\n",
    "    \n",
    "    # Process section directly with the original document\n",
    "    start_time = time.time()\n",
    "    document = extraction_service.process_document_section(\n",
    "        document=document,\n",
    "        section_id=section.section_id\n",
    "    )\n",
    "    extraction_time = time.time() - start_time\n",
    "    print(f\"Extraction for section {section.section_id} completed in {extraction_time:.2f} seconds\")\n",
    "    \n",
    "print(f\"\\nExtraction for first {n} sections complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show extraction results...\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"section_id\": \"1\",\n",
      "    \"classification\": \"letter\",\n",
      "    \"confidence\": 1.0,\n",
      "    \"page_ids\": [\n",
      "      \"1\",\n",
      "      \"2\"\n",
      "    ],\n",
      "    \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/1/result.json\"\n",
      "  },\n",
      "  {\n",
      "    \"section_id\": \"2\",\n",
      "    \"classification\": \"email\",\n",
      "    \"confidence\": 1.0,\n",
      "    \"page_ids\": [\n",
      "      \"3\",\n",
      "      \"4\"\n",
      "    ],\n",
      "    \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/2/result.json\"\n",
      "  },\n",
      "  {\n",
      "    \"section_id\": \"3\",\n",
      "    \"classification\": \"invoice\",\n",
      "    \"confidence\": 1.0,\n",
      "    \"page_ids\": [\n",
      "      \"5\"\n",
      "    ],\n",
      "    \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/3/result.json\"\n",
      "  }\n",
      "]...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nShow extraction results...\\n\")\n",
    "\n",
    "document_dict = document.to_dict()\n",
    "sections_json = json.dumps(document_dict[\"sections\"][:n], indent=2)\n",
    "print(f\"{sections_json}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Document Status Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Document State:\n",
      "Document ID: rvl-cdip-package\n",
      "Status: COMPLETED\n",
      "Number of pages: 10\n",
      "Number of sections: 7\n",
      "\n",
      "Document can be serialized to JSON:\n",
      "{\n",
      "  \"id\": \"rvl-cdip-package\",\n",
      "  \"input_bucket\": \"idp-notebook-input-912625584728-us-west-2\",\n",
      "  \"input_key\": \"sample-2025-05-22_17-19-44.pdf\",\n",
      "  \"output_bucket\": \"idp-notebook-output-912625584728-us-west-2\",\n",
      "  \"status\": \"COMPLETED\",\n",
      "  \"initial_event_time\": null,\n",
      "  \"queued_time\": null,\n",
      "  \"start_time\": null,\n",
      "  \"completion_time\": null,\n",
      "  \"workflow_execution_arn\": null,\n",
      "  \"num_pages\": 10,\n",
      "  \"summary_report_uri\": null,\n",
      "  \"evaluation_status\": null,\n",
      "  \"evaluation_report_uri\": null,\n",
      "  \"errors\": [],\n",
      "  \"metering\": {\n",
      "    \"textract/analyze_document-Layout\": {\n",
      "      \"pages\": 10\n",
      "    },\n",
      "    \"bedrock/us.amazon.nova-pro-v1:0\": {\n",
      "      \"inputTokens\": 10504,\n",
      "      \"outputTokens\": 376,\n",
      "      \"totalTokens\": 15028,\n",
      "      \"cacheReadInputTokens\": 0,\n",
      "      \"cacheWriteInputTokens\": 4148\n",
      "    }\n",
      "  },\n",
      "  \"pages\": {\n",
      "    \"1\": {\n",
      "      \"page_id\": \"1\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/1/result.json\",\n",
      "      \"classification\": \"letter\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"page_id\": \"2\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/2/result.json\",\n",
      "      \"classification\": \"letter\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"page_id\": \"3\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/3/result.json\",\n",
      "      \"classification\": \"email\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"page_id\": \"4\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/4/result.json\",\n",
      "      \"classification\": \"email\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"page_id\": \"5\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/5/result.json\",\n",
      "      \"classification\": \"invoice\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"page_id\": \"6\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/6/result.json\",\n",
      "      \"classification\": \"advertisement\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"page_id\": \"7\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/7/result.json\",\n",
      "      \"classification\": \"questionnaire\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"page_id\": \"8\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/8/result.json\",\n",
      "      \"classification\": \"resume\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"page_id\": \"9\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/9/result.json\",\n",
      "      \"classification\": \"resume\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"page_id\": \"10\",\n",
      "      \"image_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/image.jpg\",\n",
      "      \"raw_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/rawText.json\",\n",
      "      \"parsed_text_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/pages/10/result.json\",\n",
      "      \"classification\": \"memo\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"tables\": [],\n",
      "      \"forms\": {}\n",
      "    }\n",
      "  },\n",
      "  \"sections\": [\n",
      "    {\n",
      "      \"section_id\": \"1\",\n",
      "      \"classification\": \"letter\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"1\",\n",
      "        \"2\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/1/result.json\"\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"2\",\n",
      "      \"classification\": \"email\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"3\",\n",
      "        \"4\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/2/result.json\"\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"3\",\n",
      "      \"classification\": \"invoice\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"5\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": \"s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/3/result.json\"\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"4\",\n",
      "      \"classification\": \"advertisement\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"6\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": null\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"5\",\n",
      "      \"classification\": \"questionnaire\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"7\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": null\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"6\",\n",
      "      \"classification\": \"resume\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"8\",\n",
      "        \"9\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": null\n",
      "    },\n",
      "    {\n",
      "      \"section_id\": \"7\",\n",
      "      \"classification\": \"memo\",\n",
      "      \"confidence\": 1.0,\n",
      "      \"page_ids\": [\n",
      "        \"10\"\n",
      "      ],\n",
      "      \"extraction_result_uri\": null\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Update document status to COMPLETED\n",
    "document.status = Status.COMPLETED\n",
    "\n",
    "# Display final document state\n",
    "print(\"Final Document State:\")\n",
    "print(f\"Document ID: {document.id}\")\n",
    "print(f\"Status: {document.status.value}\")\n",
    "print(f\"Number of pages: {document.num_pages}\")\n",
    "print(f\"Number of sections: {len(document.sections)}\")\n",
    "\n",
    "# Show document serialization capabilities\n",
    "print(\"\\nDocument can be serialized to JSON:\")\n",
    "document_dict = document.to_dict()\n",
    "document_json = json.dumps(document_dict, indent=2)  \n",
    "print(f\"{document_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Results\n",
    "\n",
    "In this section, we'll demonstrate how to evaluate extraction results by comparing them with expected (ground truth) values. The evaluation process involves:\n",
    "\n",
    "1. Creating a ground truth document with expected values\n",
    "2. Comparing the actual extraction results against expected values\n",
    "3. Calculating metrics (precision, recall, F1 score)\n",
    "4. Generating an evaluation report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create a ground truth document from an existing document and expected results\n",
    "def create_ground_truth_document(source_document, expected_results_dict):\n",
    "    \"\"\"Creates a ground truth document for evaluation from an existing document and expected results.\n",
    "    \n",
    "    Args:\n",
    "        source_document: The original document to copy structure from\n",
    "        expected_results_dict: Dictionary mapping section IDs to expected attribute values\n",
    "        \n",
    "    Returns:\n",
    "        Document: A document with the same structure but with expected results\n",
    "    \"\"\"\n",
    "    # Create a new document with the same core attributes\n",
    "    ground_truth = Document(\n",
    "        id=source_document.id,\n",
    "        input_bucket=source_document.input_bucket,\n",
    "        input_key=source_document.input_key,\n",
    "        output_bucket=source_document.output_bucket,\n",
    "        status=Status.COMPLETED\n",
    "    )\n",
    "    \n",
    "    # Copy sections and add expected result URIs\n",
    "    for section in source_document.sections:\n",
    "        # Create section with same structure\n",
    "        expected_section = Section(\n",
    "            section_id=section.section_id,\n",
    "            classification=section.classification,\n",
    "            confidence=1.0,\n",
    "            page_ids=section.page_ids.copy(),\n",
    "            extraction_result_uri=section.extraction_result_uri  # Copy the URI from actual document\n",
    "        )\n",
    "        ground_truth.sections.append(expected_section)\n",
    "    \n",
    "    # Copy pages\n",
    "    for page_id, page in source_document.pages.items():\n",
    "        ground_truth.pages[page_id] = page\n",
    "    \n",
    "    # Store expected results to S3 for sections that have extraction results\n",
    "    for section_id, expected_data in expected_results_dict.items():\n",
    "        # Find the section in the document\n",
    "        for section in ground_truth.sections:\n",
    "            if section.section_id == section_id and section.extraction_result_uri:\n",
    "                # Load the original extraction result as template\n",
    "                uri = section.extraction_result_uri\n",
    "                bucket, key = parse_s3_uri(uri)\n",
    "                \n",
    "                try:\n",
    "                    # Get the original result structure\n",
    "                    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "                    result_data = json.loads(response['Body'].read().decode('utf-8'))\n",
    "                    \n",
    "                    # Replace the inference_result with our expected data\n",
    "                    if \"inference_result\" in result_data:\n",
    "                        result_data[\"inference_result\"] = expected_data\n",
    "                    else:\n",
    "                        # Or just replace the entire content if no inference_result key\n",
    "                        result_data = expected_data\n",
    "                    \n",
    "                    # Write back to S3 with a different key for expected values\n",
    "                    expected_key = key.replace(\"/result.json\", \"/expected.json\")\n",
    "                    s3_client.put_object(\n",
    "                        Bucket=bucket,\n",
    "                        Key=expected_key,\n",
    "                        Body=json.dumps(result_data).encode('utf-8')\n",
    "                    )\n",
    "                    \n",
    "                    # Update the section's extraction URI to point to our expected data\n",
    "                    section.extraction_result_uri = f\"s3://{bucket}/{expected_key}\"\n",
    "                    print(f\"Stored expected results for section {section_id} at {section.extraction_result_uri}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error storing expected results for section {section_id}: {e}\")\n",
    "    \n",
    "    return ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored expected results for section 1 at s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/1/expected.json\n",
      "Stored expected results for section 2 at s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/2/expected.json\n",
      "Stored expected results for section 3 at s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/3/expected.json\n"
     ]
    }
   ],
   "source": [
    "# Define expected results for extraction (ground truth)\n",
    "# Customize values to showcase different evaluation methods from CONFIG\n",
    "expected_results = {\n",
    "    \"1\": {  # Section 1 (Letter)\n",
    "        # For sender_name with LLM matching - intentionally create a variant that should match semantically\n",
    "        \"sender_name\": \"William E. Clarke\",  \n",
    "        # For sender_address with LLM matching - formatting differences should still match\n",
    "        \"sender_address\": \"206 maple Street\\nP.O. Box 1056\\nMurray Kentucky 42071-1056\"  \n",
    "    },\n",
    "    \"2\": {  # Section 2 (Form)\n",
    "        # For form_type with FUZZY matching (threshold 0.7) - added qualifier but should still match\n",
    "        \"form_type\": \"LAB SERVICES CONSISTENCY REPORT - Annual Edition\",  \n",
    "        # For form_id with NUMERIC_EXACT - should match\n",
    "        \"form_id\": 2030053328  \n",
    "    },\n",
    "    \"3\": {  # Section 3 (Email)\n",
    "        # For from_address with default matching (LLM) - match\n",
    "        \"from_address\": \"Kelahan, Benjamin\",  \n",
    "        # For to_address field with LLM matching\n",
    "        \"to_address\": \"TI Minnesota, TI New York\"  \n",
    "    }\n",
    "}\n",
    "\n",
    "# Create ground truth document using the helper function\n",
    "expected_document = create_ground_truth_document(document, expected_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:idp_common.evaluation.service:Initialized evaluation service with LLM configuration and max_workers=10\n",
      "WARNING:idp_common.evaluation.service:Missing extraction URI for section: 4\n",
      "WARNING:idp_common.evaluation.service:Missing extraction URI for section: 5\n",
      "WARNING:idp_common.evaluation.service:Section 5 evaluation returned no result\n",
      "WARNING:idp_common.evaluation.service:Section 4 evaluation returned no result\n",
      "WARNING:idp_common.evaluation.service:Missing extraction URI for section: 6\n",
      "WARNING:idp_common.evaluation.service:Missing extraction URI for section: 7\n",
      "WARNING:idp_common.evaluation.service:Section 6 evaluation returned no result\n",
      "WARNING:idp_common.evaluation.service:Section 7 evaluation returned no result\n",
      "DEBUG:idp_common.evaluation.service:Evaluating Section 1 - class: letter, content: Section(section_id='1', classification='letter', confidence=1.0, page_ids=['1', '2'], extraction_result_uri='s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/1/result.json', attributes=None)\n",
      "INFO:idp_common.evaluation.service:Comparing: sender_name using EvaluationMethod.LLM - from class letter\n",
      "INFO:idp_common.evaluation.service:Comparing: sender_address using EvaluationMethod.LLM - from class letter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running document evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-lite-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0}\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are an evaluator that helps determine if the predicted and expected values match for document attribute extraction. You will consider the context and meaning rather than just exact string matching.'}]\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': 'I need to evaluate attribute extraction for a document of class: letter.\\n\\nFor the attribute named \"sender_name\" described as \"The name of the person or entity who wrote or sent the letter. Look for text following or near terms like \\'from\\', \\'sender\\', \\'authored by\\', \\'written by\\', or at the end of the letter before a signature.\":\\n- Expected value: William E. Clarke\\n- Actual value: Will E. Clark\\n\\nDo these values match in meaning, taking into account formatting differences, word order, abbreviations, and semantic equivalence?\\nProvide your assessment as a JSON with three fields:\\n- \"match\": boolean (true if they match, false if not)\\n- \"score\": number between 0 and 1 representing the confidence/similarity score\\n- \"reason\": brief explanation of your decision\\n\\nRespond ONLY with the JSON and nothing else. Here\\'s the exact format:\\n{\\n  \"match\": true or false,\\n  \"score\": 0.0 to 1.0,\\n  \"reason\": \"Your explanation here\"\\n}'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "DEBUG:idp_common.bedrock.client:No cachepoint tags in text content, passing through unchanged\n",
      "INFO:idp_common.bedrock.client:Bedrock request attempt 1/8:\n",
      "DEBUG:idp_common.bedrock.client:  - model: us.amazon.nova-lite-v1:0\n",
      "DEBUG:idp_common.bedrock.client:  - inferenceConfig: {'temperature': 0.0}\n",
      "DEBUG:idp_common.evaluation.service:Evaluating Section 3 - class: invoice, content: Section(section_id='3', classification='invoice', confidence=1.0, page_ids=['5'], extraction_result_uri='s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/3/result.json', attributes=None)\n",
      "DEBUG:idp_common.bedrock.client:  - system: [{'text': 'You are an evaluator that helps determine if the predicted and expected values match for document attribute extraction. You will consider the context and meaning rather than just exact string matching.'}]\n",
      "INFO:idp_common.evaluation.service:Comparing: invoice_number using EvaluationMethod.LLM - from class invoice\n",
      "DEBUG:idp_common.bedrock.client:  - messages: [{'role': 'user', 'content': [{'text': 'I need to evaluate attribute extraction for a document of class: letter.\\n\\nFor the attribute named \"sender_address\" described as \"The physical address of the sender, typically appearing at the top of the letter. May be labeled as \\'address\\', \\'location\\', or \\'from address\\'.\":\\n- Expected value: 206 maple Street\\nP.O. Box 1056\\nMurray Kentucky 42071-1056\\n- Actual value: 206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056\\n\\nDo these values match in meaning, taking into account formatting differences, word order, abbreviations, and semantic equivalence?\\nProvide your assessment as a JSON with three fields:\\n- \"match\": boolean (true if they match, false if not)\\n- \"score\": number between 0 and 1 representing the confidence/similarity score\\n- \"reason\": brief explanation of your decision\\n\\nRespond ONLY with the JSON and nothing else. Here\\'s the exact format:\\n{\\n  \"match\": true or false,\\n  \"score\": 0.0 to 1.0,\\n  \"reason\": \"Your explanation here\"\\n}'}]}]\n",
      "DEBUG:idp_common.bedrock.client:  - additionalModelRequestFields: {'inferenceConfig': {'topK': 5}}\n",
      "INFO:idp_common.evaluation.service:Comparing: from_address using EvaluationMethod.LLM - from class invoice\n",
      "INFO:idp_common.evaluation.service:Comparing: invoice_date using EvaluationMethod.LLM - from class invoice\n",
      "INFO:idp_common.evaluation.service:Comparing: to_address using EvaluationMethod.LLM - from class invoice\n",
      "DEBUG:idp_common.evaluation.service:Evaluating Section 2 - class: email, content: Section(section_id='2', classification='email', confidence=1.0, page_ids=['3', '4'], extraction_result_uri='s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/sections/2/result.json', attributes=None)\n",
      "INFO:idp_common.evaluation.service:Comparing: from_address using EvaluationMethod.LLM - from class email\n",
      "INFO:idp_common.evaluation.service:Comparing: to_address using EvaluationMethod.LLM - from class email\n",
      "INFO:idp_common.evaluation.service:Comparing: form_id using EvaluationMethod.LLM - from class email\n",
      "INFO:idp_common.evaluation.service:Comparing: form_type using EvaluationMethod.LLM - from class email\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 0.61s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': '5df71179-cbcd-4a22-a732-c03069dba052', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:20:06 GMT', 'content-type': 'application/json', 'content-length': '484', 'connection': 'keep-alive', 'x-amzn-requestid': '5df71179-cbcd-4a22-a732-c03069dba052'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n  \"match\": true,\\n  \"score\": 0.9,\\n  \"reason\": \"The actual value \\'Will E. Clark\\' is a shortened and slightly altered version of the expected value \\'William E. Clarke\\'. Both names refer to the same person, considering common abbreviations and variations in name formatting.\"\\n}\\n```'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 255, 'outputTokens': 71, 'totalTokens': 326}, 'metrics': {'latencyMs': 541}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 255, 'outputTokens': 71, 'totalTokens': 326}\n",
      "DEBUG:idp_common.bedrock.client:Bedrock request successful after 1 attempts. Duration: 0.69s\n",
      "INFO:idp_common.bedrock.client:Response: {'ResponseMetadata': {'RequestId': 'e01f6ada-cc44-489f-a859-2b17f95ea449', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 22 May 2025 17:20:06 GMT', 'content-type': 'application/json', 'content-length': '391', 'connection': 'keep-alive', 'x-amzn-requestid': 'e01f6ada-cc44-489f-a859-2b17f95ea449'}, 'RetryAttempts': 0}, 'output': {'message': {'role': 'assistant', 'content': [{'text': '```json\\n{\\n  \"match\": true,\\n  \"score\": 0.99,\\n  \"reason\": \"The actual value matches the expected value in meaning despite minor differences in formatting such as capitalization and spacing.\"\\n}\\n```'}]}}, 'stopReason': 'end_turn', 'usage': {'inputTokens': 290, 'outputTokens': 47, 'totalTokens': 337}, 'metrics': {'latencyMs': 478}}\n",
      "INFO:idp_common.bedrock.client:Token Usage: {'inputTokens': 290, 'outputTokens': 47, 'totalTokens': 337}\n",
      "INFO:idp_common.evaluation.service:Evaluation complete for document rvl-cdip-package in 2.15 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed in 2.49 seconds\n",
      "Evaluation report URI: s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/evaluation/report.md\n"
     ]
    }
   ],
   "source": [
    "# Create the evaluation service\n",
    "evaluation_service = evaluation.EvaluationService(config=CONFIG)\n",
    "\n",
    "# Run evaluation\n",
    "print(\"Running document evaluation...\")\n",
    "start_time = time.time()\n",
    "document = evaluation_service.evaluate_document(\n",
    "    actual_document=document,\n",
    "    expected_document=expected_document\n",
    ")\n",
    "evaluation_time = time.time() - start_time\n",
    "\n",
    "print(f\"Evaluation completed in {evaluation_time:.2f} seconds\")\n",
    "print(f\"Evaluation report URI: {document.evaluation_report_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result object\n",
      "DocumentEvaluationResult(document_id='rvl-cdip-package', section_results=[SectionEvaluationResult(section_id='1', document_class='letter', attributes=[AttributeEvaluationResult(name='sender_address', expected='206 maple Street\\nP.O. Box 1056\\nMurray Kentucky 42071-1056', actual='206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056', matched=True, score=0.99, reason='The actual value matches the expected value in meaning despite minor differences in formatting such as capitalization and spacing.', error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='sender_name', expected='William E. Clarke', actual='Will E. Clark', matched=True, score=0.9, reason=\"The actual value 'Will E. Clark' is a shortened and slightly altered version of the expected value 'William E. Clarke'. Both names refer to the same person, considering common abbreviations and variations in name formatting.\", error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None)], metrics={'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'accuracy': 1.0, 'false_alarm_rate': 0.0, 'false_discovery_rate': 0.0}), SectionEvaluationResult(section_id='2', document_class='email', attributes=[AttributeEvaluationResult(name='form_id', expected=2030053328, actual=None, matched=False, score=0.0, reason='[Default method - attribute not specified in the configuration]', error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='form_type', expected='LAB SERVICES CONSISTENCY REPORT - Annual Edition', actual=None, matched=False, score=0.0, reason='[Default method - attribute not specified in the configuration]', error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='from_address', expected=None, actual='Kelahan, Ben', matched=False, score=0.0, reason=None, error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='to_address', expected=None, actual=\"TI New York; 'TI Minnesota\", matched=False, score=0.0, reason=None, error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None)], metrics={'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'accuracy': 0.0, 'false_alarm_rate': 1.0, 'false_discovery_rate': 0.0}), SectionEvaluationResult(section_id='3', document_class='invoice', attributes=[AttributeEvaluationResult(name='from_address', expected='Kelahan, Benjamin', actual=None, matched=False, score=0.0, reason='[Default method - attribute not specified in the configuration]', error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='invoice_date', expected=None, actual='11/12/1992', matched=False, score=0.0, reason=None, error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='invoice_number', expected=None, actual='86239', matched=False, score=0.0, reason=None, error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None), AttributeEvaluationResult(name='to_address', expected='TI Minnesota, TI New York', actual=None, matched=False, score=0.0, reason='[Default method - attribute not specified in the configuration]', error_details=None, evaluation_method='LLM', evaluation_threshold=None, comparator_type=None)], metrics={'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0, 'accuracy': 0.0, 'false_alarm_rate': 1.0, 'false_discovery_rate': 0.0})], overall_metrics={'precision': 0.3333333333333333, 'recall': 0.3333333333333333, 'f1_score': 0.3333333333333333, 'accuracy': 0.2, 'false_alarm_rate': 1.0, 'false_discovery_rate': 0.0}, execution_time=2.1532294750213623, output_uri=None)\n",
      "Reading markdown report from S3...\n",
      "Successfully read report from s3://idp-notebook-output-912625584728-us-west-2/sample-2025-05-22_17-19-44.pdf/evaluation/report.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Document Evaluation: rvl-cdip-package\n",
       "\n",
       "## Summary\n",
       "- **Match Rate**:  2/10 attributes matched [] 20%\n",
       "- **Precision**: 0.33 | **Recall**: 0.33 | **F1 Score**:  0.33\n",
       "\n",
       "## Overall Metrics\n",
       "| Metric | Value | Rating |\n",
       "| ------ | :----: | :----: |\n",
       "| precision | 0.3333 |  Poor |\n",
       "| recall | 0.3333 |  Poor |\n",
       "| f1_score | 0.3333 |  Poor |\n",
       "| accuracy | 0.2000 |  Poor |\n",
       "| false_alarm_rate | 1.0000 |  Poor |\n",
       "| false_discovery_rate | 0.0000 |  Excellent |\n",
       "\n",
       "\n",
       "## Section: 1 (letter)\n",
       "### Metrics\n",
       "| Metric | Value | Rating |\n",
       "| ------ | :----: | :----: |\n",
       "| precision | 1.0000 |  Excellent |\n",
       "| recall | 1.0000 |  Excellent |\n",
       "| f1_score | 1.0000 |  Excellent |\n",
       "| accuracy | 1.0000 |  Excellent |\n",
       "| false_alarm_rate | 0.0000 |  Excellent |\n",
       "| false_discovery_rate | 0.0000 |  Excellent |\n",
       "\n",
       "\n",
       "### Attributes\n",
       "| Status | Attribute | Expected | Actual | Score | Method | Reason |\n",
       "| :----: | --------- | -------- | ------ | ----- | ------ | ------ |\n",
       "|  | sender_address | 206 maple Street P.O. Box 1056 Murray Kentucky 42071-1056 | 206 Maple Street P.O. Box 1056 Murray Kentucky 42071-1056 | 0.99 | LLM | The actual value matches the expected value in meaning despite minor differences in formatting such as capitalization and spacing. |\n",
       "|  | sender_name | William E. Clarke | Will E. Clark | 0.90 | LLM | The actual value 'Will E. Clark' is a shortened and slightly altered version of the expected value 'William E. Clarke'. Both names refer to the same person, considering common abbreviations and variations in name formatting. |\n",
       "\n",
       "\n",
       "## Section: 2 (email)\n",
       "### Metrics\n",
       "| Metric | Value | Rating |\n",
       "| ------ | :----: | :----: |\n",
       "| precision | 0.0000 |  Poor |\n",
       "| recall | 0.0000 |  Poor |\n",
       "| f1_score | 0.0000 |  Poor |\n",
       "| accuracy | 0.0000 |  Poor |\n",
       "| false_alarm_rate | 1.0000 |  Poor |\n",
       "| false_discovery_rate | 0.0000 |  Excellent |\n",
       "\n",
       "\n",
       "### Attributes\n",
       "| Status | Attribute | Expected | Actual | Score | Method | Reason |\n",
       "| :----: | --------- | -------- | ------ | ----- | ------ | ------ |\n",
       "|  | form_id | 2030053328 | None | 0.00 | LLM | [Default method - attribute not specified in the configuration] |\n",
       "|  | form_type | LAB SERVICES CONSISTENCY REPORT - Annual Edition | None | 0.00 | LLM | [Default method - attribute not specified in the configuration] |\n",
       "|  | from_address | None | Kelahan, Ben | 0.00 | LLM |  |\n",
       "|  | to_address | None | TI New York; 'TI Minnesota | 0.00 | LLM |  |\n",
       "\n",
       "\n",
       "## Section: 3 (invoice)\n",
       "### Metrics\n",
       "| Metric | Value | Rating |\n",
       "| ------ | :----: | :----: |\n",
       "| precision | 0.0000 |  Poor |\n",
       "| recall | 0.0000 |  Poor |\n",
       "| f1_score | 0.0000 |  Poor |\n",
       "| accuracy | 0.0000 |  Poor |\n",
       "| false_alarm_rate | 1.0000 |  Poor |\n",
       "| false_discovery_rate | 0.0000 |  Excellent |\n",
       "\n",
       "\n",
       "### Attributes\n",
       "| Status | Attribute | Expected | Actual | Score | Method | Reason |\n",
       "| :----: | --------- | -------- | ------ | ----- | ------ | ------ |\n",
       "|  | from_address | Kelahan, Benjamin | None | 0.00 | LLM | [Default method - attribute not specified in the configuration] |\n",
       "|  | invoice_date | None | 11/12/1992 | 0.00 | LLM |  |\n",
       "|  | invoice_number | None | 86239 | 0.00 | LLM |  |\n",
       "|  | to_address | TI Minnesota, TI New York | None | 0.00 | LLM | [Default method - attribute not specified in the configuration] |\n",
       "\n",
       "\n",
       "Execution time: 2.15 seconds\n",
       "\n",
       "## Evaluation Methods Used\n",
       "\n",
       "This evaluation used the following methods to compare expected and actual values:\n",
       "\n",
       "1. **EXACT** - Exact string match after stripping punctuation and whitespace\n",
       "2. **NUMERIC_EXACT** - Exact numeric match after normalizing\n",
       "3. **FUZZY** - Fuzzy string matching using string similarity metrics (with evaluation_threshold)\n",
       "4. **SEMANTIC** - Semantic similarity comparison using Bedrock Titan embeddings (with evaluation_threshold)\n",
       "5. **HUNGARIAN** - Bipartite matching algorithm for lists of values\n",
       "   - **EXACT** - Hungarian matching with exact string comparison\n",
       "   - **FUZZY** - Hungarian matching with fuzzy string comparison (with evaluation_threshold)\n",
       "   - **NUMERIC** - Hungarian matching with numeric comparison\n",
       "6. **LLM** - Advanced semantic evaluation using Bedrock large language models\n",
       "\n",
       "Each attribute is configured with a specific evaluation method based on the data type and comparison needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show structured evaluation result\n",
    "print(\"Evaluation result object\")\n",
    "if document.evaluation_result:\n",
    "    print(f\"{document.evaluation_result}\")\n",
    "else:\n",
    "    print(\"ERROR.. No evaluation_result found\")\n",
    "\n",
    "# Read the evaluation report from S3\n",
    "print(\"Reading markdown report from S3...\")\n",
    "if document.evaluation_report_uri:\n",
    "    bucket, key = parse_s3_uri(document.evaluation_report_uri)\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    s3_markdown = response['Body'].read().decode('utf-8')\n",
    "    print(f\"Successfully read report from {document.evaluation_report_uri}\")\n",
    "else:\n",
    "    print(\"No evaluation report URI found\")\n",
    "\n",
    "# Display the report in the notebook with proper formatting\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Display the markdown directly from S3 content\n",
    "display(Markdown(s3_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Clean Up (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete objects in a bucket\n",
    "def delete_bucket_objects(bucket_name):\n",
    "    try:\n",
    "        # List all objects in the bucket\n",
    "        response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "        if 'Contents' in response:\n",
    "            delete_keys = {'Objects': [{'Key': obj['Key']} for obj in response['Contents']]}\n",
    "            s3_client.delete_objects(Bucket=bucket_name, Delete=delete_keys)\n",
    "            print(f\"Deleted all objects in bucket {bucket_name}\")\n",
    "        else:\n",
    "            print(f\"Bucket {bucket_name} is already empty\")\n",
    "            \n",
    "        # Delete bucket\n",
    "        s3_client.delete_bucket(Bucket=bucket_name)\n",
    "        print(f\"Deleted bucket {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning up bucket {bucket_name}: {str(e)}\")\n",
    "\n",
    "# Uncomment the following lines to delete the buckets\n",
    "# print(\"Cleaning up resources...\")\n",
    "# delete_bucket_objects(input_bucket_name)\n",
    "# delete_bucket_objects(output_bucket_name)\n",
    "# print(\"Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the end-to-end processing flow using AWS services and the unified Document model:\n",
    "\n",
    "1. **Document Creation** - Initialize a Document object with input/output locations\n",
    "2. **OCR Processing** - Convert PDF to text using AWS Textract via OcrService\n",
    "3. **Classification** - Identify document types and sections with Claude via ClassificationService\n",
    "4. **Extraction** - Extract structured information with Claude via ExtractionService\n",
    "5. **Evaluation** - Compare extraction results against expected values and generate metrics\n",
    "6. **Document Model** - Document object is consistently used between all services\n",
    "7. **Result Storage** - Extraction results are stored in S3 with URIs tracked in the Document\n",
    "\n",
    "Key benefits of this approach:\n",
    "\n",
    "1. **Modularity** - Each service has a clear responsibility\n",
    "2. **Consistency** - Same data model flows through the entire pipeline\n",
    "3. **Performance** - Focused document pattern reduces resource usage\n",
    "4. **Flexibility** - Support for multiple backends (Bedrock, SageMaker)\n",
    "5. **Maintainability** - Standardized patterns across services\n",
    "6. **Measurement** - Built-in evaluation capabilities to measure accuracy\n",
    "\n",
    "This example uses a  workflow with:\n",
    "1. S3 buckets (created specifically for this demo)\n",
    "2. AWS Textract OCR processing\n",
    "3. LLM inferencing via Bedrock\n",
    "4. A document sample (rvl_cdip_package.pdf)\n",
    "\n",
    "The Evaluation Service specifically provides:\n",
    "\n",
    "1. Multiple evaluation methods (EXACT, NUMERIC_EXACT, FUZZY)\n",
    "2. Per-attribute and document-level metrics\n",
    "3. Markdown and JSON format reporting\n",
    "4. Integration with the Document model\n",
    "5. Configuration-driven evaluation methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
