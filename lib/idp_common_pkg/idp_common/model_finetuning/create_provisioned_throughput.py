#!/usr/bin/env python3
"""
Nova Provisioned Throughput Creation Script

This script creates and manages provisioned throughput for fine-tuned Nova models. It can:
1. Create provisioned throughput for completed fine-tuning jobs
2. Monitor provisioning status
3. Delete provisioned throughput to avoid costs
4. Load job details from previous fine-tuning runs

Prerequisites:
- Set up AWS CLI: `aws configure`
- Install required packages: `pip install boto3 python-dotenv`
- Have a completed fine-tuning job
- Appropriate AWS permissions for Bedrock

Example usage:
    python create_provisioned_throughput.py \
        --model-id arn:aws:bedrock:us-east-1:123456789012:custom-model/amazon.nova-lite-v1... \
        --provisioned-model-name my-provisioned-model \
        --model-units 1

    python create_provisioned_throughput.py \
        --job-details-file finetuning_job_20241201_120000.json \
        --provisioned-model-name my-provisioned-model \
        --model-units 2

    python create_provisioned_throughput.py \
        --delete \
        --provisioned-model-arn arn:aws:bedrock:us-east-1:123456789012:provisioned-model/...
"""

import argparse
import json
import logging
import time
from datetime import datetime
from typing import Dict, Optional

import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv

from idp_common.model_finetuning import (
    ModelFinetuningService,
    ProvisionedThroughputConfig,
    ProvisionedThroughputResult,
)

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ProvisionedThroughputManager:
    """Manages Nova provisioned throughput."""
    
    def __init__(self, region: str = "us-east-1"):
        """Initialize provisioned throughput manager."""
        self.region = region
        self.service = ModelFinetuningService(region=region)
        self.bedrock_client = boto3.client('bedrock', region_name=region)
        
    def create_provisioned_throughput(self, config: ProvisionedThroughputConfig) -> ProvisionedThroughputResult:
        """Create provisioned throughput."""
        logger.info(f"Creating provisioned throughput: {config.provisioned_model_name}")
        logger.info(f"Model ID: {config.model_id}")
        logger.info(f"Model units: {config.model_units}")
        
        result = self.service.create_provisioned_throughput(config)
        logger.info(f"Provisioned throughput created successfully: {result.provisioned_model_arn}")
        
        return result
    
    def monitor_provisioning(self, provisioned_model_arn: str, polling_interval: int = 30,
                           max_wait_time: Optional[int] = None) -> ProvisionedThroughputResult:
        """
        Monitor provisioning progress.
        
        Args:
            provisioned_model_arn: Provisioned model ARN to monitor
            polling_interval: Time between status checks (seconds)
            max_wait_time: Maximum time to wait (seconds)
            
        Returns:
            Final provisioning result
        """
        logger.info(f"Monitoring provisioning: {provisioned_model_arn}")
        
        result = self.service.wait_for_provisioning_completion(
            provisioned_model_arn,
            model_type="nova",
            polling_interval=polling_interval,
            max_wait_time=max_wait_time
        )
        
        logger.info(f"Provisioning completed with status: {result.status}")
        return result
    
    def get_provisioning_status(self, provisioned_model_arn: str) -> ProvisionedThroughputResult:
        """Get current provisioning status."""
        return self.service.get_provisioned_throughput_status(provisioned_model_arn, model_type="nova")
    
    def delete_provisioned_throughput(self, provisioned_model_arn: str) -> Dict:
        """Delete provisioned throughput."""
        logger.info(f"Deleting provisioned throughput: {provisioned_model_arn}")
        
        response = self.service.delete_provisioned_throughput(provisioned_model_arn, model_type="nova")
        logger.info("Provisioned throughput deletion initiated successfully")
        
        return response
    
    def list_provisioned_models(self) -> list:
        """List all provisioned models."""
        try:
            response = self.bedrock_client.list_provisioned_model_throughputs()
            return response.get('provisionedModelSummaries', [])
        except ClientError as e:
            logger.error(f"Error listing provisioned models: {e}")
            return []
    
    def save_provisioning_details(self, result: ProvisionedThroughputResult, output_file: str = None):
        """Save provisioning details to JSON file."""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"provisioned_throughput_{timestamp}.json"
        
        provisioning_data = {
            "provisioned_model_arn": result.provisioned_model_arn,
            "provisioned_model_id": result.provisioned_model_id,
            "status": result.status,
            "creation_time": result.creation_time,
            "failure_reason": result.failure_reason,
            "model_type": result.model_type
        }
        
        with open(output_file, 'w') as f:
            json.dump(provisioning_data, f, indent=2)
        
        logger.info(f"Provisioning details saved to: {output_file}")
        return output_file


def load_job_details(job_details_file: str) -> Dict:
    """Load job details from JSON file."""
    try:
        with open(job_details_file, 'r') as f:
            job_data = json.load(f)
        logger.info(f"Loaded job details from: {job_details_file}")
        return job_data
    except FileNotFoundError:
        logger.error(f"Job details file not found: {job_details_file}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"Error parsing job details file: {e}")
        raise


def get_model_id_from_job_arn(job_arn: str, region: str = "us-east-1") -> str:
    """Get model ID from completed fine-tuning job ARN."""
    bedrock_client = boto3.client('bedrock', region_name=region)
    
    try:
        response = bedrock_client.get_model_customization_job(jobIdentifier=job_arn)
        model_id = response.get('outputModelArn')
        
        if not model_id:
            raise ValueError(f"No output model found for job: {job_arn}")
        
        logger.info(f"Retrieved model ID from job: {model_id}")
        return model_id
        
    except ClientError as e:
        logger.error(f"Error retrieving job details: {e}")
        raise


def main():
    """Main function to create and manage provisioned throughput."""
    parser = argparse.ArgumentParser(
        description="Create and manage Nova provisioned throughput",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Create provisioned throughput with model ID
  python create_provisioned_throughput.py \\
    --model-id arn:aws:bedrock:us-east-1:123456789012:custom-model/amazon.nova-lite-v1... \\
    --provisioned-model-name my-provisioned-model \\
    --model-units 1
  
  # Create provisioned throughput from job details file
  python create_provisioned_throughput.py \\
    --job-details-file finetuning_job_20241201_120000.json \\
    --provisioned-model-name my-provisioned-model \\
    --model-units 2
  
  # Create provisioned throughput from job ARN
  python create_provisioned_throughput.py \\
    --job-arn arn:aws:states:us-east-1:123456789012:execution:... \\
    --provisioned-model-name my-provisioned-model
  
  # Check status of provisioned throughput
  python create_provisioned_throughput.py \\
    --status-only \\
    --provisioned-model-arn arn:aws:bedrock:us-east-1:123456789012:provisioned-model/...
  
  # Delete provisioned throughput
  python create_provisioned_throughput.py \\
    --delete \\
    --provisioned-model-arn arn:aws:bedrock:us-east-1:123456789012:provisioned-model/...
  
  # List all provisioned models
  python create_provisioned_throughput.py --list-models
        """
    )
    
    # Mutually exclusive group for model identification
    model_group = parser.add_mutually_exclusive_group()
    model_group.add_argument("--model-id",
                           help="Fine-tuned model ID/ARN")
    model_group.add_argument("--job-details-file",
                           help="JSON file with fine-tuning job details")
    model_group.add_argument("--job-arn",
                           help="Fine-tuning job ARN")
    
    # Required for creation (unless using other modes)
    parser.add_argument("--provisioned-model-name",
                       help="Name for the provisioned model")
    parser.add_argument("--model-units", type=int, default=1,
                       help="Number of model units (default: 1)")
    
    # Optional arguments
    parser.add_argument("--region", default="us-east-1",
                       help="AWS region (default: us-east-1)")
    
    # Monitoring options
    parser.add_argument("--no-wait", action="store_true",
                       help="Don't wait for provisioning completion")
    parser.add_argument("--polling-interval", type=int, default=30,
                       help="Status check interval in seconds (default: 30)")
    parser.add_argument("--max-wait-time", type=int, default=1800,
                       help="Maximum time to wait in seconds (default: 1800)")
    
    # Output options
    parser.add_argument("--output-file",
                       help="File to save provisioning details (default: auto-generated)")
    
    # Action modes
    parser.add_argument("--status-only", action="store_true",
                       help="Only check status of existing provisioned throughput")
    parser.add_argument("--delete", action="store_true",
                       help="Delete existing provisioned throughput")
    parser.add_argument("--list-models", action="store_true",
                       help="List all provisioned models")
    parser.add_argument("--provisioned-model-arn",
                       help="Provisioned model ARN for status/delete operations")
    
    args = parser.parse_args()
    
    # Validate arguments
    if args.status_only or args.delete:
        if not args.provisioned_model_arn:
            parser.error("--status-only and --delete require --provisioned-model-arn")
    
    if args.list_models:
        # List models mode - no other arguments needed
        pass
    elif args.status_only or args.delete:
        # Status/delete modes - no model ID needed
        pass
    elif not (args.model_id or args.job_details_file or args.job_arn):
        parser.error("Must specify --model-id, --job-details-file, or --job-arn for creation")
    
    if not (args.status_only or args.delete or args.list_models) and not args.provisioned_model_name:
        parser.error("--provisioned-model-name is required for creation")
    
    try:
        # Initialize manager
        manager = ProvisionedThroughputManager(args.region)
        
        # List models mode
        if args.list_models:
            logger.info("Listing all provisioned models...")
            models = manager.list_provisioned_models()
            
            if not models:
                print("No provisioned models found.")
                return 0
            
            print(f"\nFound {len(models)} provisioned model(s):")
            print("-" * 80)
            for model in models:
                print(f"Name: {model.get('provisionedModelName', 'N/A')}")
                print(f"ARN: {model.get('provisionedModelArn', 'N/A')}")
                print(f"Status: {model.get('status', 'N/A')}")
                print(f"Model Units: {model.get('modelUnits', 'N/A')}")
                print(f"Foundation Model: {model.get('foundationModelArn', 'N/A')}")
                print(f"Creation Time: {model.get('creationTime', 'N/A')}")
                print("-" * 80)
            
            return 0
        
        # Status-only mode
        if args.status_only:
            logger.info(f"Checking status for provisioned throughput: {args.provisioned_model_arn}")
            result = manager.get_provisioning_status(args.provisioned_model_arn)
            
            print(f"Provisioning Status: {result.status}")
            print(f"Provisioned Model ARN: {result.provisioned_model_arn}")
            print(f"Creation Time: {result.creation_time}")
            if result.failure_reason:
                print(f"Failure Reason: {result.failure_reason}")
            
            return 0
        
        # Delete mode
        if args.delete:
            logger.info(f"Deleting provisioned throughput: {args.provisioned_model_arn}")
            
            # Confirm deletion
            response = input(f"Are you sure you want to delete provisioned throughput '{args.provisioned_model_arn}'? (yes/no): ")
            if response.lower() not in ['yes', 'y']:
                logger.info("Deletion cancelled.")
                return 0
            
            manager.delete_provisioned_throughput(args.provisioned_model_arn)
            logger.info("‚úÖ Provisioned throughput deletion initiated successfully!")
            logger.info("Note: It may take a few minutes for the deletion to complete.")
            
            return 0
        
        # Creation mode - determine model ID
        model_id = None
        
        if args.model_id:
            model_id = args.model_id
        elif args.job_details_file:
            job_data = load_job_details(args.job_details_file)
            
            if job_data.get('model_id'):
                model_id = job_data['model_id']
            elif job_data.get('job_arn'):
                model_id = get_model_id_from_job_arn(job_data['job_arn'], args.region)
            else:
                logger.error("Job details file does not contain model_id or job_arn")
                return 1
        elif args.job_arn:
            model_id = get_model_id_from_job_arn(args.job_arn, args.region)
        
        if not model_id:
            logger.error("Could not determine model ID")
            return 1
        
        # Create provisioned throughput configuration
        config = ProvisionedThroughputConfig(
            model_id=model_id,
            provisioned_model_name=args.provisioned_model_name,
            model_units=args.model_units,
            model_type="nova"
        )
        
        # Create provisioned throughput
        result = manager.create_provisioned_throughput(config)
        
        # Save provisioning details
        output_file = manager.save_provisioning_details(result, args.output_file)
        
        # Monitor provisioning if requested
        if not args.no_wait:
            logger.info("Monitoring provisioning progress...")
            final_result = manager.monitor_provisioning(
                result.provisioned_model_arn,
                args.polling_interval,
                args.max_wait_time
            )
            
            # Update saved provisioning details
            manager.save_provisioning_details(final_result, output_file)
            
            if final_result.status == "InService":
                logger.info("‚úÖ Provisioned throughput is ready!")
                logger.info(f"Provisioned Model ARN: {final_result.provisioned_model_arn}")
                logger.info("You can now use this model for inference.")
            elif final_result.status == "Failed":
                logger.error("‚ùå Provisioning failed!")
                if final_result.failure_reason:
                    logger.error(f"Failure reason: {final_result.failure_reason}")
                return 1
            else:
                logger.info(f"Provisioning finished with status: {final_result.status}")
        else:
            logger.info("Provisioning initiated successfully. Use --status-only to check progress later.")
        
        logger.info(f"Provisioning details saved to: {output_file}")
        logger.info("\n" + "="*60)
        logger.info("üí° IMPORTANT: Provisioned throughput incurs costs!")
        logger.info("üí° Use --delete to remove when no longer needed.")
        logger.info("="*60)
        
        return 0
        
    except Exception as e:
        logger.error(f"Error during provisioned throughput operation: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
